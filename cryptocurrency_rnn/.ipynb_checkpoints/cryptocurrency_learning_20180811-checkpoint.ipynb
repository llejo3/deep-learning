{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = Client('', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUR_FORMAT = '%Y/%m/%d %H:%M:%S'\n",
    "\n",
    "def to_date(date_str) :\n",
    "    return datetime.datetime.strptime(date_str, HOUR_FORMAT)\n",
    "\n",
    "def to_hour_str(timestamp) :\n",
    "    if isinstance(timestamp, pd.Series) :\n",
    "        return  pd.DatetimeIndex(pd.to_datetime(timestamp, unit='ms')).tz_localize('UTC').tz_convert('Asia/Seoul').strftime(HOUR_FORMAT)\n",
    "    elif isinstance(timestamp, datetime.datetime) : \n",
    "        return timestamp.strftime(HOUR_FORMAT)\n",
    "    else :\n",
    "        return datetime.datetime.fromtimestamp(timestamp/1000).strftime(HOUR_FORMAT)\n",
    "\n",
    "    \n",
    "def get_klines_binance_data(symbol, start) :\n",
    "    TZ_STR = ' KST'\n",
    "    client = Client('', '')\n",
    "    klines = []\n",
    "    if start == '' :\n",
    "        now_datetime = datetime.datetime.today()\n",
    "        start = to_hour_str(now_datetime - datetime.timedelta(days=365)) \n",
    "        end = to_hour_str(now_datetime - datetime.timedelta(hours=1)) \n",
    "        #print(end)\n",
    "        while True :\n",
    "            klines_new = client.get_historical_klines(symbol, Client.KLINE_INTERVAL_1HOUR, start + TZ_STR, end + TZ_STR)\n",
    "            if len(klines_new) == 0:\n",
    "                break\n",
    "            klines = klines_new +  klines   \n",
    "            end = to_hour_str(to_date(start) - datetime.timedelta(hours=1))  \n",
    "            start = to_hour_str(to_date(start) - datetime.timedelta(days=365))  \n",
    "    else :    \n",
    "        klines = client.get_historical_klines(symbol, Client.KLINE_INTERVAL_1HOUR, start + TZ_STR)\n",
    "        klines = klines[:-1]\n",
    "    \n",
    "    df_klines = pd.DataFrame(klines, columns=['open-time', 'open', 'high', 'low', 'close', 'volume', \n",
    "                                              'close-time', 'quote-volume', 'trades-cnt', \n",
    "                                              'taker-base-volume', 'taker-quote-volume', 'unknown'])   \n",
    "    df_klines = df_klines.assign(hour = to_hour_str(df_klines['open-time']))\n",
    "    df_klines = df_klines[['hour', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    return df_klines\n",
    "    \n",
    "def get_klines_data(symbol) :\n",
    "    file_path = './data/' + symbol + '.csv'\n",
    "    if os.path.isfile(file_path) :\n",
    "        data = pd.read_csv(file_path)\n",
    "        data = data[:-1]\n",
    "        hours_last = data.tail(1)['hour'].to_string(index=False)\n",
    "        hour_next = to_hour_str(to_date(hours_last) + datetime.timedelta(hours=1))\n",
    "        new_data = get_klines_binance_data(symbol, hour_next)\n",
    "        if len(new_data) > 0 :\n",
    "            data = data.append(new_data, ignore_index=True)\n",
    "            data.to_csv(file_path, index=False)\n",
    "            data = pd.read_csv(file_path)\n",
    "    else :\n",
    "        data = get_klines_binance_data(symbol, '')\n",
    "        data.to_csv(file_path, index=False)\n",
    "        data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# matrix 데이터로 변경한다.\n",
    "def to_ndarray(cols_data) :\n",
    "    if isinstance(cols_data, Series):\n",
    "        return np.reshape(list(cols_data), (-1,1))\n",
    "    elif isinstance(cols_data, DataFrame):\n",
    "        return cols_data.as_matrix()\n",
    "\n",
    "# 컬럼을 스케일링을 시킨다.\n",
    "def get_scaled_cols(data, column_name) :\n",
    "    scale_data = to_ndarray(data[column_name])\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(scale_data), scaler;\n",
    "\n",
    "# 데이터를 스케일링 시킨다.\n",
    "def get_scaled_data(data) :\n",
    "    scaled_data = data.copy()\n",
    "    scaled_data = scaled_data[['close', 'open', 'high', 'low', 'volume']]\n",
    "    scaled_data = scaled_data[scaled_data['close']!=0]\n",
    "    scaled_data['close'], scaler_close = get_scaled_cols(scaled_data, 'close')\n",
    "    scaled_data['open'], _ = get_scaled_cols(scaled_data, 'open')\n",
    "    scaled_data['high'], _ = get_scaled_cols(scaled_data, 'high')\n",
    "    scaled_data['low'], _ = get_scaled_cols(scaled_data, 'low')\n",
    "    scaled_data['volume'], _ = get_scaled_cols(scaled_data, 'volume')\n",
    "    return scaled_data, scaler_close;\n",
    "\n",
    "# RNN을 위한 데이터로 만든다. \n",
    "def get_dataXY(data) :\n",
    "    x = to_ndarray(data)\n",
    "    y = to_ndarray(data['close'])\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    seq_length = params['seq_length']\n",
    "    y_len = len(y)\n",
    "    for i in range(0, y_len - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        _y = y[i + seq_length] # Next close price\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    dataX_last = [x[y_len-seq_length: y_len]]    \n",
    "    return dataX, dataY, y, dataX_last\n",
    "\n",
    "# train 및 test 데이터로 나눈다.\n",
    "def split_train_test(dataX, dataY, data, y) :\n",
    "    invest_count = params['invest_count']\n",
    "    seq_length = params['seq_length']\n",
    "    data_count = len(dataY);\n",
    "    train_size = int(data_count * params['train_percent'] / 100)\n",
    "    train_last = data_count-invest_count;\n",
    "    \n",
    "    trainX = np.array(dataX[0:train_size])\n",
    "    testX = np.array(dataX[train_size:train_last])\n",
    "    investX = np.array(dataX[train_last:data_count])\n",
    "    \n",
    "    trainY = np.array(dataY[0:train_size])\n",
    "    testY = np.array(dataY[train_size:train_last])\n",
    "    investY = np.array(dataY[train_last:data_count])\n",
    "    \n",
    "    trainCloses = np.array( y[seq_length-1:train_size+seq_length-1])\n",
    "    testCloses = np.array(dataY[train_size-1:train_last-1])\n",
    "    investCloses = np.array(dataY[train_last-1:data_count-1])\n",
    "    investRealCloses = np.array(data['close'][train_last-1+seq_length:data_count+seq_length].values)\n",
    "    #print(investRealCloses)\n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY, 'trainCloses': trainCloses,\n",
    "        'testX': testX, 'testY': testY, 'testCloses' : testCloses,\n",
    "        'investX': investX,'investY': investY, 'investCloses': investCloses, 'investRealCloses': investRealCloses\n",
    "    }\n",
    "\n",
    "# train, test데이터로 만든다.\n",
    "def get_train_test(data) :\n",
    "    scaled_data, scaler_close = get_scaled_data(data)\n",
    "    dataX, dataY, y, dataX_last = get_dataXY(scaled_data)\n",
    "    return split_train_test(dataX, dataY, data, y), scaler_close, dataX_last\n",
    "\n",
    "# 텐스플로우 변수관계 그래프롤 그린다.\n",
    "def draw_graph() :\n",
    "    seq_length = params['seq_length']\n",
    "    data_dim = params['data_dim']\n",
    "    hidden_dims = params['hidden_dims']\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "    X_closes = tf.placeholder(tf.float32, [None, 1])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "    output_keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    cells = []\n",
    "    for n in hidden_dims :\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_units=n, activation=tf.tanh)\n",
    "        dropout_cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=output_keep_prob)\n",
    "        cells.append(dropout_cell)\n",
    "    stacked_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(stacked_rnn_cell, X, dtype=tf.float32) \n",
    "    Y_pred = tf.contrib.layers.fully_connected(\n",
    "        outputs[:, -1], params['output_dim'], activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "    # cost/loss\n",
    "    loss = tf.reduce_sum(tf.square(1-(1+Y_pred-X_closes)/(1+Y-X_closes)))\n",
    "        \n",
    "    optimizer = tf.train.AdamOptimizer(params['learning_rate'])\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # RMSE\n",
    "    targets = tf.placeholder(tf.float32, [None, 1])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(1-(1+predictions-X_closes)/(1+targets-X_closes))))\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'output_keep_prob': output_keep_prob,\n",
    "        'train': train,\n",
    "        'loss' : loss,\n",
    "        'Y_pred': Y_pred,\n",
    "        'targets': targets,\n",
    "        'rmse' : rmse,\n",
    "        'predictions': predictions,\n",
    "        'X_closes' : X_closes\n",
    "    }\n",
    "\n",
    "def draw_plot(rmse_vals, test_predict, invest_predicts, symbol, data_params) :\n",
    "    testY = data_params['testY']\n",
    "    investY = data_params['investY']\n",
    "    y = np.append(testY,investY)\n",
    "    predict =  np.append(test_predict, invest_predicts)\n",
    "    \n",
    "    mpl.rcParams['axes.unicode_minus'] = False\n",
    "    font_name = fm.FontProperties(fname=params['kor_font_path'], size=50).get_name()\n",
    "    plt.rc('font', family=font_name)\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot(rmse_vals, 'gold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Root Mean Square Error')\n",
    "    plt.title(symbol)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(y, 'b')\n",
    "    plt.plot(predict, 'r')\n",
    "    plt.xlabel('Time Period')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.title(symbol)\n",
    "    plt.show()\n",
    "\n",
    "def save_learning_image(sess, saver, graph_params, symbol) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    X_closes = graph_params['X_closes']\n",
    "    train = graph_params['train']\n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    output_keep_prob = graph_params['output_keep_prob']\n",
    "    \n",
    "    tf.add_to_collection(\"X\", X)\n",
    "    tf.add_to_collection(\"X_closes\", X_closes)\n",
    "    tf.add_to_collection(\"Y\", Y)\n",
    "    tf.add_to_collection(\"train\", train)\n",
    "    tf.add_to_collection(\"Y_pred\", Y_pred)\n",
    "    tf.add_to_collection(\"output_keep_prob\", output_keep_prob)\n",
    "    saver.save(sess, \"./sessions/\" + symbol + \".ckpt\")\n",
    "    \n",
    "# 학습을 시킨다.\n",
    "def let_training(graph_params, symbol, data_params) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    output_keep_prob = graph_params['output_keep_prob']\n",
    "    train = graph_params['train']\n",
    "    loss = graph_params['loss']\n",
    "    trainX = data_params['trainX']\n",
    "    trainY = data_params['trainY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    trainCloses = data_params['trainCloses']\n",
    "    testCloses = data_params['testCloses']\n",
    "    \n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    targets = graph_params['targets']\n",
    "    rmse = graph_params['rmse']\n",
    "    predictions = graph_params['predictions']\n",
    "    X_closes = graph_params['X_closes']\n",
    "    loss_up_count = params['loss_up_count']\n",
    "    dropout_keep = params['dropout_keep']\n",
    "    iterations = params['iterations']\n",
    "    rmse_max = params['rmse_max']\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # Training step\n",
    "        min_rmse_val = 999999\n",
    "        less_cnt = 0\n",
    "        train_count = 0\n",
    "        rmse_vals = []\n",
    "        \n",
    "        for i in range(iterations[1]):\n",
    "            _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY, X_closes: trainCloses, output_keep_prob: dropout_keep})\n",
    "            test_predict = sess.run(Y_pred, feed_dict={X: testX, output_keep_prob: 1.0})\n",
    "            rmse_val = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict, X_closes: testCloses}) \n",
    "            rmse_vals.append(rmse_val)\n",
    "            if rmse_val < min_rmse_val :\n",
    "                save_learning_image(sess, saver, graph_params, symbol)\n",
    "                less_cnt = 0\n",
    "                train_count = i;\n",
    "                max_test_predict, min_rmse_val, = test_predict, rmse_val\n",
    "            else :\n",
    "                less_cnt += 1\n",
    "            if i > iterations[0] and less_cnt > loss_up_count and rmse_max > min_rmse_val:\n",
    "                break\n",
    "        #draw_plot(rmse_vals, max_test_predict, testY, comp_name) \n",
    "        return min_rmse_val, train_count, rmse_vals, max_test_predict\n",
    "\n",
    "\n",
    "# 그래프를 그리고 학습을 시킨다.    \n",
    "def let_leaning(symbol, data_params):\n",
    "    graph_params = draw_graph()\n",
    "    return let_training(graph_params, symbol, data_params)\n",
    "\n",
    "# 예측 값에 따라 매수 매도를 실행한다.    \n",
    "def let_invest_money(invest_predict, now_scaled_close, now_close, now_money, now_stock_cnt) :\n",
    "    seq_length = params['seq_length']\n",
    "    data_dim = params['data_dim']\n",
    "    fee_percent = params['fee_percent']\n",
    "    invest_min_percent = params['invest_min_percent']\n",
    "    \n",
    "    ratio = (invest_predict - now_scaled_close) /now_scaled_close * 100\n",
    "    \n",
    "    if ratio > invest_min_percent :\n",
    "        #print(now_money, now_close)\n",
    "        cnt = math.floor(now_money/now_close)\n",
    "        if cnt > 0 :\n",
    "            fee = now_close * fee_percent/100\n",
    "            now_money -= (now_close + fee) * cnt\n",
    "            now_stock_cnt += cnt\n",
    "    elif ratio < -invest_min_percent :\n",
    "        if now_stock_cnt > 0 :\n",
    "            now_money += to_money(now_close, now_stock_cnt)\n",
    "            now_stock_cnt = 0\n",
    "    return now_money, now_stock_cnt\n",
    "\n",
    "# 주식매도를 해서 돈으로 바꾼다.\n",
    "def to_money(now_stock_cnt, now_close) :\n",
    "    money = 0\n",
    "    if now_stock_cnt > 0 :\n",
    "        fee_percent = params['fee_percent'] \n",
    "        tax_percent = params['tax_percent']\n",
    "        \n",
    "        fee = now_close * fee_percent/100\n",
    "        tax = now_close * tax_percent/100\n",
    "        money = (now_close - (fee + tax)) * now_stock_cnt\n",
    "    return money\n",
    "    \n",
    "# 학습 후 모의 주식 거래를 한다.\n",
    "def let_invest(symbol, train_cnt, dataX_last, data_params):\n",
    "    invest_count = params['invest_count']\n",
    "    invest_money = params['invest_money']\n",
    "    dropout_keep = params['dropout_keep']\n",
    "    \n",
    "    investX = data_params['investX']\n",
    "    investCloses = data_params['investCloses']\n",
    "    investRealCloses = data_params['investRealCloses']\n",
    "    investX = data_params['investX']\n",
    "    investY = data_params['investY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    testCloses = data_params['testCloses']\n",
    "    \n",
    "    now_stock_cnt = 0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        saver.restore(sess, \"./sessions/\" + symbol + \".ckpt\") \n",
    "        X = tf.get_collection('X')[0]\n",
    "        X_closes = tf.get_collection('X_closes')[0]\n",
    "        Y = tf.get_collection('Y')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "        Y_pred = tf.get_collection('Y_pred')[0]\n",
    "        output_keep_prob = tf.get_collection('output_keep_prob')[0]\n",
    "        \n",
    "        for i in range(int(train_cnt)):\n",
    "            sess.run(train, feed_dict={X: testX, Y: testY, X_closes: testCloses, \n",
    "                                       output_keep_prob: dropout_keep})\n",
    "        predicts = []\n",
    "        now_close = 0\n",
    "        for i in range(invest_count) :\n",
    "            np.array([1, 2, 3], ndmin=2)\n",
    "            invest_predicts = sess.run(Y_pred, feed_dict={X: investX[i:i+1], output_keep_prob: 1.0})\n",
    "            predicts.append(invest_predicts[0])\n",
    "            \n",
    "            invest_predict = invest_predicts[0][0];\n",
    "            now_scaled_close = investCloses[0][0]\n",
    "            now_close = investRealCloses[i]\n",
    "            #print(invest_predict, now_scaled_close, now_close)\n",
    "            invest_money, now_stock_cnt = let_invest_money(invest_predict, now_scaled_close, now_close,\n",
    "                                                           invest_money, now_stock_cnt)\n",
    "            for i in range(int(train_cnt/5)):\n",
    "                sess.run(train, feed_dict={X: investX[i:i+1], Y: investY[i:i+1], X_closes: investCloses[i:i+1], \n",
    "                                           output_keep_prob: dropout_keep})\n",
    "            #break\n",
    "        invest_money += to_money(now_stock_cnt, now_close)\n",
    "        graph_params = {'X':X, 'X_closes':X_closes, 'Y':Y, 'train':train, \n",
    "                        'Y_pred':Y_pred, 'output_keep_prob':output_keep_prob}\n",
    "        save_learning_image(sess, saver, graph_params, symbol)\n",
    "        saver.save(sess, \"./sessions/\" + symbol + \".ckpt\")\n",
    "        \n",
    "        last_predict = sess.run(Y_pred, feed_dict={X: dataX_last, output_keep_prob: 1.0})\n",
    "    #print(now_money)\n",
    "    return invest_money, last_predict, predicts\n",
    "\n",
    "# 실제 가격을 가져온다.\n",
    "def get_real_money(data_params, scaler_close, last_predict) :\n",
    "    investRealCloses = data_params['investRealCloses'];\n",
    "    predict_money = scaler_close.inverse_transform(last_predict)\n",
    "    last_close_money = investRealCloses[len(investRealCloses)-1]\n",
    "    last_pred_money = predict_money[0][0]\n",
    "    return last_close_money, last_pred_money\n",
    "\n",
    "# 다음날 종가를 예측한다.\n",
    "def predict_next_close(symbol) :\n",
    "    data = get_klines_data(symbol)\n",
    "    data_params, scaler_close, dataX_last = get_train_test(data)\n",
    "    rmse_val, train_cnt, rmse_vals, test_predict  = let_leaning(symbol, data_params)\n",
    "    last_money, last_predict, invest_predicts = let_invest(symbol, train_cnt, dataX_last, data_params)\n",
    "    draw_plot(rmse_vals, test_predict, invest_predicts, symbol, data_params)\n",
    "    last_close_money, last_pred_money = get_real_money(data_params, scaler_close, last_predict)\n",
    "    print(\"RMSE:\", rmse_val)\n",
    "    print(\"train_cnt:\", train_cnt)\n",
    "    if params['invest_count'] > 0 :\n",
    "        print(str(params['invest_count']) + \"회 모의투자 결과:\", \"{:,.0f}\".format(last_money))\n",
    "    last_date = data.tail(1)['hour'].to_string(index=False)\n",
    "    \n",
    "    #print(\"마지막 종가(\" + last_date + \"):\", \"{:,.0f}\".format(last_close_money))\n",
    "    print(\"마지막 종가(\" + last_date + \"):\", last_close_money)\n",
    "    last_pred_ratio = (last_pred_money-last_close_money)/last_close_money * 100\n",
    "    #last_pred_ratio = \"(\" + \"{:.2f}\".format(last_pred_ratio) + \"%)\"\n",
    "    last_pred_ratio = \"(\" + last_pred_ratio + \"%)\"\n",
    "    #print(\"예측 종가:\", \"{:,.0f}\".format( last_pred_money ), last_pred_ratio)\n",
    "    print(\"예측 종가:\", last_pred_money , last_pred_ratio)\n",
    "    print()\n",
    "\n",
    "# 다음날 종가를 예측한다.\n",
    "def predict_invest(symbol) :\n",
    "    data = get_klines_data(symbol)\n",
    "    data_params, scaler_close, dataX_last = get_train_test(data)\n",
    "    rmse_val, train_cnt, rmse_vals, test_predict  = let_leaning(symbol, data_params)\n",
    "    last_money, last_predict, invest_predicts = let_invest(symbol, train_cnt, dataX_last, data_params)\n",
    "    draw_plot(rmse_vals, test_predict, invest_predicts, symbol, data_params)\n",
    "    last_close_money, last_pred_money = get_real_money(data_params, scaler_close, last_predict)\n",
    "    print(\"RMSE:\", rmse_val)\n",
    "    print(\"train_cnt:\", train_cnt)\n",
    "    if params['invest_count'] > 0 :\n",
    "        print(str(params['invest_count']) + \"회 모의투자 결과:\", \"{:,.0f}\".format(last_money))\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seq_length' : 24, # 시퀀스 갯수\n",
    "    'data_dim' : 5,    # 입력 데이터 갯수\n",
    "    'hidden_dims' : [128, 96, 64],  # 히든 레이어 갯수 \n",
    "    'dropout_keep' : 0.8, # dropout \n",
    "    'output_dim' : 1,  # 출력 데이터 갯수\n",
    "    'learning_rate' : 0.0001, \n",
    "    'iterations' : [40, 200],  # 최소, 최대 훈련 반복횟수\n",
    "    'rmse_max' : 0.045,\n",
    "    'train_percent' : 80.0, # 훈련 데이터 퍼센트\n",
    "    'loss_up_count' : 36, # early stopping\n",
    "    'invest_count' : 24*7,  # 투자 횟수\n",
    "    'invest_money' : 100000, # 각 주식에 모의투자할 금액\n",
    "    'fee_percent' : 0.05, # 투자시 발생하는 수수료\n",
    "    'tax_percent' : 0.0,   # 매도시 발생하는 세금\n",
    "    'invest_min_percent' : 0.1, # 투자를 하는 최소 간격 퍼센트 \n",
    "    'kor_font_path' : 'C:\\\\WINDOWS\\\\Fonts\\\\H2GTRM.TTF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\south\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype <U32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./sessions/ETHUSDT.ckpt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-527e21efcd9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msymbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"ETHUSDT\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"BTCUSDT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"EOSUSDT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BCCUSDT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ADAUSDT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BNBUSDT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IOTAUSDT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msymbol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msymbols\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpredict_invest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-e73db8f009f3>\u001b[0m in \u001b[0;36mpredict_invest\u001b[1;34m(symbol)\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[0mdata_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler_close\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataX_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[0mrmse_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_cnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mlet_leaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m     \u001b[0mlast_money\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvest_predicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlet_invest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_cnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataX_last\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m     \u001b[0mdraw_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvest_predicts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[0mlast_close_money\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_pred_money\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_money\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler_close\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e73db8f009f3>\u001b[0m in \u001b[0;36mlet_invest\u001b[1;34m(symbol, train_cnt, dataX_last, data_params)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;31m#print(invest_predict, now_scaled_close, now_close)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             invest_money, now_stock_cnt = let_invest_money(invest_predict, now_scaled_close, now_close,\n\u001b[1;32m--> 357\u001b[1;33m                                                            invest_money, now_stock_cnt)\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cnt\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                 sess.run(train, feed_dict={X: investX[i:i+1], Y: investY[i:i+1], X_closes: investCloses[i:i+1], \n",
      "\u001b[1;32m<ipython-input-3-e73db8f009f3>\u001b[0m in \u001b[0;36mlet_invest_money\u001b[1;34m(invest_predict, now_scaled_close, now_close, now_money, now_stock_cnt)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0minvest_min_percent\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;31m#print(now_money, now_close)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m         \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow_money\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnow_close\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0mfee\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow_close\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfee_percent\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "symbols = [\"ETHUSDT\",\"BTCUSDT\", \"EOSUSDT\", \"BCCUSDT\", \"ADAUSDT\", \"BNBUSDT\", \"IOTAUSDT\"]\n",
    "for symbol in symbols :\n",
    "    predict_invest(symbol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
