{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_zip = zipfile.ZipFile('./Stock_Dataset(2017_07_06).zip')\n",
    "fantasy_zip.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Using cached https://files.pythonhosted.org/packages/07/e6/e95c4eec6221bfd8528bcc4ea252a850bffcc4be88ebc367e23a1a84b0bb/xlrd-1.1.0-py2.py3-none-any.whl\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "Collecting jdcal (from openpyxl)\n",
      "  Using cached https://files.pythonhosted.org/packages/a0/38/dcf83532480f25284f3ef13f8ed63e03c58a65c9d3ba2a6a894ed9497207/jdcal-1.4-py2.py3-none-any.whl\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jdcal, et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.0.1 jdcal-1.4 openpyxl-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 255,
=======
   "execution_count": 129,
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
   "metadata": {},
   "outputs": [],
   "source": [
    "### 메소드 정의 \n",
    "# 상세 데이터를 가져온다.\n",
    "def get_stock_datail(comp_code) :\n",
    "    code = format(comp_code, \"06d\");\n",
    "    return pd.read_csv('./data/' + code + '.csv')\n",
    "\n",
    "# matrix 데이터로 변경한다.\n",
    "def to_ndarray(cols_data) :\n",
    "    if isinstance(cols_data, Series):\n",
    "        return np.reshape(list(cols_data), (-1,1))\n",
    "    elif isinstance(cols_data, DataFrame):\n",
    "        return cols_data.as_matrix()\n",
    "\n",
    "# 컬럼을 스케일링을 시킨다.\n",
    "def get_scaled_cols(data, column_name) :\n",
    "    scale_data = to_ndarray(data[column_name])\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(scale_data);\n",
    "\n",
    "# 데이터를 스케일링 시킨다.\n",
    "def get_scaled_data(data) :\n",
    "    scaled_data = data.copy()\n",
    "    scaled_data['Close'] = get_scaled_cols(scaled_data, 'Close')\n",
    "    scaled_data['Open'] = get_scaled_cols(scaled_data, 'Open')\n",
    "    scaled_data['High'] = get_scaled_cols(scaled_data, 'High')\n",
    "    scaled_data['Low'] = get_scaled_cols(scaled_data, 'Low')\n",
    "    scaled_data['Volume'] = get_scaled_cols(scaled_data, 'Volume')\n",
    "    return scaled_data;\n",
    "\n",
    "# RNN을 위한 데이터로 만든다. \n",
    "def get_dataXY(data, train_params) :\n",
    "    x = to_ndarray(data[['Open', 'High', 'Low', 'Volume', 'Close']])\n",
    "    y = to_ndarray(data['Close'])\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    seq_length = train_params['seq_length']\n",
    "    for i in range(0, len(y) - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        _y = y[i + seq_length] # Next close price\n",
    "        #print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return dataX, dataY\n",
    "\n",
    "# train 및 test 데이터로 나눈다.\n",
    "def split_train_test(dataX, dataY, train_params, data) :\n",
    "    invest_count = train_params['invest_count']\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_count = len(dataY);\n",
    "    train_size = int(data_count * train_params['train_percent'] / 100)\n",
    "    train_last = data_count-invest_count;\n",
    "    \n",
    "    trainX = np.array(dataX[0:train_size])\n",
    "    testX = np.array(dataX[train_size:train_last])\n",
    "    investX = np.array(dataX[train_last:data_count])\n",
    "    \n",
    "    trainY = np.array(dataY[0:train_size])\n",
    "    testY = np.array(dataY[train_size:train_last])\n",
<<<<<<< HEAD
    "    investY = np.array(dataY[train_last:data_count])\n",
    "    \n",
    "    #trainCloses = np.array( y[seq_length-1:train_size+seq_length-1])\n",
    "    testCloses = np.array(dataY[train_size-1:train_last-1])\n",
    "    investCloses = np.array(dataY[train_last-1:data_count-1])\n",
    "    investRealCloses = np.array(data['Close'][train_last-1+seq_length:data_count-1+seq_length].values)\n",
    "    \n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY,\n",
    "        'testX': testX, 'testY': testY, 'testCloses' : testCloses,\n",
    "        'investX': investX,'investY': investY, 'investCloses': investCloses, 'investRealCloses': investRealCloses\n",
=======
    "    \n",
    "    #rainCloses = np.array( y[seq_length-1:train_size+seq_length-1])\n",
    "    testCloses = np.array(dataY[train_size-1:train_last-1])\n",
    "    #investY = np.array(dataY[train_last:data_count])\n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY,\n",
    "        'testX': testX, 'testY': testY, 'testCloses' : testCloses,\n",
    "        #'investX': investX,'investY': investY\n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "    }\n",
    "\n",
    "def split_train_test_for_invest(dataX, dataY, train_params, index, data) :\n",
    "    invest_count = train_params['invest_count']\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_count = len(dataY);\n",
    "    train_size = data_count - invest_count + index\n",
    "    real_index = train_size + seq_length - 1\n",
    "    \n",
    "    trainX = np.array(dataX[0:train_size])\n",
    "    testX = np.array(dataX[train_size:train_size+1])\n",
    "    realClose = data['Close'][real_index:real_index+1].values[0]\n",
    "    \n",
    "    trainY = np.array(dataY[0:train_size])\n",
    "    testY = np.array(dataY[train_size:train_size+1])\n",
    "    \n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY, \n",
    "        'testX': testX, 'testY': testY,\n",
    "        'realClose': realClose\n",
    "    }\n",
    "\n",
    "# train, test데이터로 만든다.\n",
    "def get_train_test(data, train_params) :\n",
    "    scaled_data = get_scaled_data(data)\n",
    "    dataX, dataY = get_dataXY(scaled_data, train_params)\n",
    "    return split_train_test(dataX, dataY, train_params, data)\n",
    "\n",
    "def get_train_test_for_invest(data, train_params, index) :\n",
    "    scaled_data = get_scaled_data(data)\n",
    "    dataX, dataY, y = get_dataXY(scaled_data, train_params)\n",
    "    return split_train_test_for_invest(dataX, dataY, train_params, index, data)\n",
    "\n",
    "# 텐스플로우 변수관계 그래프롤 그린다.\n",
    "def draw_graph(train_params) :\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=train_params['hidden_dim'], \n",
    "                                        state_is_tuple=True, \n",
    "                                        activation=tf.tanh)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32 )\n",
    "    Y_pred = tf.contrib.layers.fully_connected(\n",
    "        outputs[:, -1], train_params['output_dim'], activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "    # cost/loss\n",
    "    #closes = tf.placeholder(tf.float32, [None, 1])\n",
    "    loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "    #loss = tf.reduce_sum(-1 * tf.minimum (tf.sign(closes-Y_pred) * tf.sign(closes-Y), 0)) \n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(train_params['learning_rate'])\n",
    "    # optimizer = tf.train.RMSPropOptimizer(train_params['learning_rate'])\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # RMSE\n",
    "    targets = tf.placeholder(tf.float32, [None, 1])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "    \n",
    "    closes = tf.placeholder(tf.float32, [None, 1])\n",
    "    direction_success =tf.reduce_mean(tf.maximum(tf.sign(closes-targets) * tf.sign(closes-predictions), 0))\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'train': train,\n",
    "        'loss' : loss,\n",
    "        'Y_pred': Y_pred,\n",
    "        'targets': targets,\n",
    "        'rmse' : rmse,\n",
    "        'predictions': predictions,\n",
    "        'closes' : closes,\n",
    "        'direction_success' : direction_success\n",
    "    }\n",
    "\n",
    "# 학습을 시킨다.\n",
    "def let_training(data_params, train_params, graph_params, comp_code) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    train = graph_params['train']\n",
    "    loss = graph_params['loss']\n",
    "    trainX = data_params['trainX']\n",
    "    trainY = data_params['trainY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    testCloses = data_params['testCloses']\n",
    "    \n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    targets = graph_params['targets']\n",
    "    rmse = graph_params['rmse']\n",
    "    predictions = graph_params['predictions']\n",
    "    closes = graph_params['closes']\n",
    "    direction_success = graph_params['direction_success']\n",
<<<<<<< HEAD
    "    loss_up_cnt = train_params['loss_up_cnt']\n",
=======
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # Training step\n",
    "        min_rmse_val = 999999\n",
    "        max_direction_success_val = 0\n",
    "        less_cnt = 0\n",
    "        train_count = 0\n",
    "        for i in range(train_params['iterations']):\n",
    "            _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
<<<<<<< HEAD
    "            if i % 100 == 0 :\n",
    "                test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "                rmse_val, direction_success_val = sess.run([rmse,  direction_success], \n",
    "                                                feed_dict={targets: testY, predictions: test_predict, closes: testCloses}) \n",
    "                #print(step_loss, rmse_val, direction_success_val)\n",
    "                if rmse_val < min_rmse_val :\n",
    "                #if direction_success_val > max_direction_success_val :\n",
    "                    tf.add_to_collection(\"X\", X)\n",
    "                    tf.add_to_collection(\"Y\", Y)\n",
    "                    tf.add_to_collection(\"train\", train)\n",
    "                    tf.add_to_collection(\"Y_pred\", Y_pred)\n",
    "                    saver.save(sess, \"./sessions/\" + str(comp_code) + \".ckpt\")\n",
    "                    less_cnt = 0\n",
    "                    train_count = i;\n",
    "                    max_test_predict, min_rmse_val, max_direction_success_val = test_predict, rmse_val, direction_success_val\n",
    "                else :\n",
    "                    less_cnt += 1\n",
    "                if less_cnt > loss_up_cnt :\n",
    "                    break\n",
    "        \n",
    "        return max_test_predict, min_rmse_val, max_direction_success_val, train_count \n",
=======
    "            #if i%100==0 :\n",
    "        test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "        rmse_val, direction_success_val = sess.run([rmse,  direction_success], \n",
    "                                            feed_dict={targets: testY, predictions: test_predict, closes: testCloses}) \n",
    "        #print(step_loss, rmse_val, direction_success_val)\n",
    "        return test_predict, rmse_val, direction_success_val \n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "\n",
    "# 그래프를 그리고 학습을 시킨다.    \n",
    "def let_leaning(data_params, train_params, comp_code):\n",
    "    graph_params = draw_graph(train_params)\n",
    "    return let_training(data_params, train_params, graph_params, comp_code)\n",
    "\n",
    "def to_dataFrame(data, columns) :\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# excel로 저장한다.\n",
    "def save_excel(df_data, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    df_data.to_excel(writer,'Sheet1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "# 예측 값에 따라 매수 매도를 실행한다.    \n",
<<<<<<< HEAD
    "def let_invest_money(invest_predict, now_scaled_close, now_close, rain_params, now_money, now_stock_cnt) :\n",
=======
    "def let_invest_money(invest_predict, data_params, train_params, now_money, now_stock_cnt) :\n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    pie_percent = train_params['pie_percent']\n",
    "    invest_min_percent = train_params['invest_min_percent']\n",
    "    \n",
    "    pie = now_close * pie_percent/100\n",
    "    ratio = (invest_predict - now_scaled_close) /now_scaled_close * 100\n",
    "    \n",
    "    if ratio > invest_min_percent :\n",
    "        cnt = math.floor(now_money/now_close)\n",
    "        if cnt > 0 :\n",
    "            now_money -= (now_close + pie) * cnt\n",
    "            now_stock_cnt += cnt\n",
    "    elif ratio < -invest_min_percent :\n",
    "        if now_stock_cnt > 0 :\n",
    "            now_money += to_money(now_close, now_stock_cnt, train_params)\n",
    "            now_stock_cnt = 0\n",
    "    #print(now_money, now_stock_cnt, now_scaled_close, invest_predict, data_params['testY'])\n",
    "    return now_money, now_stock_cnt\n",
    "\n",
    "# 주식매도를 해서 돈으로 바꾼다.\n",
<<<<<<< HEAD
    "def to_money(now_stock_cnt, now_close, train_params) :\n",
=======
    "def to_money(data_params, now_stock_cnt) :\n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "    money = 0\n",
    "    if now_stock_cnt > 0 :\n",
    "        pie_percent = train_params['pie_percent'] \n",
    "        tax_percent = train_params['tax_percent']\n",
    "        \n",
    "        pie = now_close * pie_percent/100\n",
    "        tax = now_close * tax_percent/100\n",
    "        money = (now_close - (pie + tax)) * now_stock_cnt\n",
    "    return money\n",
    "    \n",
    "# 학습 후 모의 주식 거래를 한다.\n",
<<<<<<< HEAD
    "def let_invest(row, train_params, data_params, train_cnt):\n",
    "    comp_code = row['종목코드']\n",
=======
    "def let_invest(row, train_params):\n",
    "    comp_code = row['code']\n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "    invest_count = train_params['invest_count']\n",
    "    invest_money = train_params['invest_money']\n",
    "    investX = data_params['investX']\n",
    "    investCloses = data_params['investCloses']\n",
    "    investRealCloses = data_params['investRealCloses']\n",
    "    investX = data_params['investX']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    #print(investRealCloses)\n",
    "    \n",
    "    now_stock_cnt = 0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        saver.restore(sess, \"./sessions/\" + str(comp_code) + \".ckpt\") \n",
    "        X = tf.get_collection('X')[0]\n",
    "        Y = tf.get_collection('Y')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "        Y_pred = tf.get_collection('Y_pred')[0]\n",
    "        \n",
    "        for i in range(train_cnt):\n",
    "            sess.run(train, feed_dict={X: testX, Y: testY})\n",
    "        \n",
    "        invest_predicts = sess.run(Y_pred, feed_dict={X: investX})\n",
    "        \n",
    "        for i in range(0, invest_count) :\n",
    "            invest_predict = invest_predicts[i][0];\n",
    "            now_scaled_close = investCloses[i][0]\n",
    "            now_close = investRealCloses[i]\n",
    "            #print(invest_predict, now_scaled_close, now_close)\n",
    "            invest_money, now_stock_cnt = let_invest_money(invest_predict, now_scaled_close, now_close,\n",
    "                                                           train_params, invest_money, now_stock_cnt)\n",
    "            #break\n",
    "        invest_money += to_money(now_stock_cnt, now_close, train_params)\n",
    "    #print(now_money)\n",
    "    return invest_money"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 248,
=======
   "execution_count": 124,
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 정의 \n",
    "# train Parameters\n",
    "train_params = {\n",
<<<<<<< HEAD
    "    'seq_length' : 7, # 시퀀스 갯수\n",
=======
    "    'seq_length' : 5, # 시퀀스 갯수\n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "    'data_dim' : 5,    # 입력 데이터 갯수\n",
    "    'hidden_dim' : 5,  # 히든 레이어 갯수 \n",
    "    'output_dim' : 1,  # 출력 데이터 갯수\n",
    "    'learning_rate' : 0.001, \n",
<<<<<<< HEAD
    "    'iterations' : 100000,  # 최대 훈련 반복횟수\n",
    "    'train_percent' : 70, # 훈련 데이터 퍼센트\n",
    "    'loss_up_cnt' : 20,\n",
    "    'invest_corp_count' : 100, # 투자하는 주식회사 갯수\n",
    "    'invest_count' : 20,  # 투자 횟수\n",
    "    'invest_money' : 1000000, # 각 주식에 모의투자할 금액\n",
    "    'pie_percent' : 0.015, # 투자시 발생하는 수수료\n",
    "    'tax_percent' : 0.5,   # 매도시 발생하는 세금\n",
    "    'invest_min_percent' : 1 # 투자를 하는 최소 간격 퍼센트 \n",
=======
    "    'iterations' : 10000,  # 훈련 반복횟수\n",
    "    'train_percent' : 70, # 훈련 데이터 퍼센트\n",
    "    'invest_corp_count' : 100, # 투자하는 주식회사 갯수\n",
    "    'invest_count' : 50,  # 투자 횟수\n",
    "    'invest_money' : 1000000, # 각 주식에 모의투자할 금액\n",
    "    'pie_percent' : 0.015, # 투자시 발생하는 수수료\n",
    "    'tax_percent' : 0.5,   # 매도시 발생하는 세금\n",
    "    'invest_min_percent' : 3 # 투자를 하는 최소 간격 퍼센트 \n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식회사 데이터\n",
    "corporations = pd.read_excel('./corporations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_corps = corporations.query(\"상장일<'2005-01-01'  \")[['회사명', '종목코드']]\n",
    "print(stock_corps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
<<<<<<< HEAD
=======
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종목코드 회사명 RMSE DIRECTION_SUCC\n",
      "1460 BYC 0.034690414 0.4614486\n",
      "79160 CJ CGV 0.11054379 0.5081776\n",
      "5830 DB손해보험 0.018586112 0.48948598\n",
      "69730 DSR제강 0.024755022 0.46378505\n",
      "9440 KC그린홀딩스 0.0072239013 0.48948598\n",
      "1940 KISCO홀딩스 0.011311655 0.46845794\n",
      "23150 MH에탄올 0.006313104 0.46962616\n",
      "34310 NICE 0.007445893 0.47313085\n",
      "36530 S&T홀딩스 0.008179164 0.48948598\n",
      "17670 SK텔레콤 0.022744749 0.5186916\n",
      "12200 계양전기 0.055728626 0.4848131\n",
      "1290 골든브릿지증권 0.008835935 0.432243\n",
      "24110 기업은행 0.014371064 0.4848131\n",
      "4540 깨끗한나라 0.06144418 0.49532712\n",
      "1260 남광토건 0.007192121 0.43808413\n",
      "25860 남해화학 0.0062237233 0.48014018\n",
      "58730 다스코 0.046092037 0.46962616\n",
      "6370 대구백화점 0.015035201 0.45794392\n",
      "3540 대신증권 0.0067079645 0.4661215\n",
      "1130 대한제분 0.020259319 0.46261683\n",
      "3490 대한항공 0.011268692 0.47313085\n",
      "5880 대한해운 0.0024171034 0.5116823\n",
      "69460 대호에이엘 0.017431667 0.49299064\n",
      "24900 덕양산업 0.072817154 0.40537384\n",
      "24090 디씨엠 0.026025971 0.42640188\n",
      "4990 롯데지주 0.06388205 0.48714954\n",
      "11170 롯데케미칼 0.01529258 0.47313085\n",
      "27740 마니커 0.0024213155 0.47897196\n",
      "8560 메리츠종금증권 0.0073510907 0.48948598\n",
      "9680 모토닉 0.0029118778 0.49182242\n",
      "2760 보락 0.017540017 0.46261683\n",
      "3850 보령제약 0.020384435 0.49532712\n",
      "79660 사조해표 0.022134744 0.4906542\n",
      "2170 삼양통상 0.021402016 0.44976637\n",
      "11230 삼화전자공업 0.009825296 0.48598132\n",
      "41650 상신브레이크 0.027005345 0.48364487\n",
      "58650 세아홀딩스 0.017438948 0.46962616\n",
      "33530 세종공업 0.014014311 0.49766356\n",
      "4430 송원산업 0.019402564 0.47429907\n",
      "2870 신풍제지 0.016356733 0.50233644\n",
      "1770 신화실업 0.047401894 0.49182242\n",
      "4080 신흥 0.012799104 0.42172897\n",
      "3560 아이에이치큐 0.009139831 0.46845794\n",
      "12750 에스원 0.03645614 0.48598132\n",
      "25530 에스제이엠홀딩스 0.019959353 0.432243\n",
      "7310 오뚜기 0.070897214 0.48948598\n",
      "11330 유니켐 0.086969025 0.2897196\n"
     ]
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    }
   ],
   "source": [
    "# 주식 종목들을 가져와서 학습을 시킨다.\n",
    "comp_rmses = []\n",
    "for idx, row in stock_corps.iterrows():\n",
    "    comp_code = row['종목코드']\n",
    "    data = get_stock_datail(comp_code)\n",
    "    data_params = get_train_test(data, train_params)\n",
<<<<<<< HEAD
    "    _, rmse_val, direction_success_val, train_cnt = let_leaning(data_params, train_params, comp_code)\n",
    "    \n",
    "    now_money = let_invest(row, train_params, data_params, train_cnt)\n",
    "    if idx == 0 :\n",
    "        print('code', 'name', 'rmse', 'direction_success', 'invest_result')\n",
    "    print(comp_code, row['회사명'], rmse_val, direction_success_val, now_money)\n",
    "    comp_rmses.append([comp_code, row['회사명'], rmse_val, direction_success_val, now_money])\n",
=======
    "    _, rmse_val, direction_success_val = let_leaning(data_params, train_params, comp_code)\n",
    "    if idx == 0 :\n",
    "        print('종목코드', '회사명', 'RMSE', 'DIRECTION_SUCC')\n",
    "    print(comp_code, row['회사명'], rmse_val, direction_success_val)\n",
    "    comp_rmses.append([comp_code, row['회사명'], rmse_val, direction_success_val])\n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "    #break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 정렬하고 저장한다.\n",
<<<<<<< HEAD
    "df_comp_rmses = pd.DataFrame(comp_rmses, columns=['code', 'name', 'rmse', 'direction_success', 'invest_result'])    \n",
    "#df_comp_rmses = df_comp_rmses.sort_values('invest_result', ascending=False)\n",
=======
    "df_comp_rmses = pd.DataFrame(comp_rmses, columns=['code', 'name', 'RMSE', 'DIRECTION_SUCC'])    \n",
    "df_comp_rmses = df_comp_rmses.sort_values('DIRECTION_SUCC', ascending=False)\n",
>>>>>>> 7af799ea5b74368894addd4b0b10b4f35ac06d36
    "save_excel(df_comp_rmses, 'comp_rmses.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9320 대우부품 1040760.72\n",
      "24060 흥구석유 937478.9400000002\n",
      "4920 씨아이테크 897843.3933499998\n",
      "910 유니온 944137.487\n",
      "9410 태영건설 1000000\n",
      "9270 신원 1030444.3772499998\n",
      "10050 우리종금 1105620.52825\n",
      "10600 웰바이오텍 959434.20425\n",
      "11000 진원생명과학 971701.6725\n",
      "30000 제일기획 970424.1225000002\n",
      "27970 세하 982093.6195000001\n",
      "7110 일신석재 1059250.8354999998\n",
      "9680 모토닉 1047522.4390000002\n",
      "3480 한진중공업홀딩스 1149089.2655\n",
      "25890 한국주강 1033093.638\n",
      "140 하이트진로홀딩스 1006345.1100000001\n",
      "520 삼일제약 995895.9400000002\n",
      "25820 이구산업 987297.5830000001\n",
      "36560 영풍정밀 1009921.443\n",
      "20 동화약품 973768.5509999999\n",
      "9620 삼보산업 1035810.5800000001\n",
      "10420 한솔피엔에스 1006373.9207499999\n",
      "9730 코센 1106915.9952499997\n",
      "23760 한국캐피탈 1000000\n",
      "27740 마니커 954063.6087999999\n",
      "1840 이화공영 957439.2660000001\n",
      "15590 큐로 1000284.5144500001\n",
      "3280 흥아해운 951360.6499999999\n",
      "8350 남선알미늄 998586.58525\n",
      "1740 SK네트웍스 791916.2985\n",
      "430 대원강업 1000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8b588d30cea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_tops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_comp_rmses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'invest_corp_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_tops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnow_money\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlet_invest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'종목코드'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'회사명'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'투자결과'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b4063b8670a1>\u001b[0m in \u001b[0;36mlet_invest\u001b[0;34m(row, train_params)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvest_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mdata_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test_for_invest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlet_leaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mnow_money\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_stock_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlet_invest_money\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_money\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_stock_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mnow_money\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mto_money\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_stock_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b4063b8670a1>\u001b[0m in \u001b[0;36mlet_leaning\u001b[0;34m(data_params, train_params, comp_code)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlet_leaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mgraph_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlet_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_dataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b4063b8670a1>\u001b[0m in \u001b[0;36mlet_training\u001b[0;34m(data_params, train_params, graph_params, comp_code)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# Training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 에러률이 적은 상위 100개만 가져와서 모의투자를 실행한다.\n",
    "invest_results = []\n",
    "df_tops = df_comp_rmses[0:train_params['invest_corp_count']]\n",
    "for idx, row in df_tops.iterrows():\n",
    "    now_money = let_invest(row, train_params)\n",
    "    if idx == 0 :\n",
    "        print('종목코드', '회사명', '투자결과')\n",
    "    print(row['code'], row['name'], now_money)\n",
    "    invest_results.append([row['code'], row['name'], now_money])\n",
    "    \n",
    "df_invest_results = pd.DataFrame(invest_results, columns=['code', 'name', 'money'])    \n",
    "save_excel(df_invest_results, 'invest_result.xlsx')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
