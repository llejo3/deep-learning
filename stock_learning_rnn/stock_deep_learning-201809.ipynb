{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import os\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문자열을 데이터 형대로 변환한다.\n",
    "def to_date(date_str) :\n",
    "    date_str = date_str.replace(\" \", \"\")\n",
    "    split = \"\"\n",
    "    if date_str.find(\"-\") > -1 :\n",
    "        split = \"-\"\n",
    "    elif date_str.find(\".\") > -1 :\n",
    "        split = \".\"\n",
    "    date_format = '%Y'+ split + '%m' + split + '%d'    \n",
    "    return datetime.datetime.strptime(date_str, date_format)\n",
    "\n",
    "# excel로 저장한다.\n",
    "def save_excel(df_data, file_path):\n",
    "    writer = pd.ExcelWriter(file_path)\n",
    "    df_data.to_excel(writer,'Sheet1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "# 주식회사 정보를 가져와서 엑셀로 저장한다.    \n",
    "def save_comp_data() :\n",
    "    url = 'http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13'\n",
    "    code_df = pd.read_html(url, header=0)[0]\n",
    "    save_excel(code_df, './data/comps.xlsx')\n",
    "\n",
    "# 엘셀을 불러와서 회사 코드를 가져온다.    \n",
    "def get_comp_code(comp_name) :\n",
    "    file_path = './data/comps.xlsx'\n",
    "    \n",
    "    if os.path.isfile(file_path) == False :\n",
    "        save_comp_data()\n",
    "        \n",
    "    corporations = pd.read_excel(file_path)\n",
    "    comp_code = corporations.query(\"회사명=='{}'\".format(comp_name))['종목코드'].to_string(index=False)\n",
    "    return format(int(comp_code), \"06d\")\n",
    "\n",
    "# 네이버 금융(http://finance.naver.com)에 넣어줌\n",
    "def get_naver_url(comp_code):\n",
    "    return 'http://finance.naver.com/item/sise_day.nhn?code={code}'.format(code=comp_code)\n",
    "\n",
    "# 네이버 매일 주식정보를 가져온다.\n",
    "def get_stock_naver_data(comp_code, start_date) :\n",
    "    url = get_naver_url(comp_code)\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # 네이버 웹 크롤링\n",
    "    page = 1\n",
    "    bf_date = ''\n",
    "    while True :\n",
    "        pg_url = '{url}&page={page}'.format(url=url, page=page)\n",
    "        page_data = pd.read_html(pg_url, header=0)[0]\n",
    "        page_data = page_data.dropna()\n",
    "        last_date = page_data.tail(1)['날짜'].to_string(index=False)\n",
    "        if bf_date == last_date :\n",
    "            break\n",
    "        df = df.append(page_data, ignore_index=True)\n",
    "        if start_date != '' :\n",
    "            if to_date(start_date) > to_date(last_date) :\n",
    "                break\n",
    "        if len(page_data) < 10 :\n",
    "            break        \n",
    "        page += 1\n",
    "        bf_date = last_date \n",
    "    \n",
    "    # 필요 없는 날짜 제거\n",
    "    if start_date != '' :\n",
    "        drop_cnt = 0\n",
    "        df_len = len(df)\n",
    "        for i in range(df_len) :\n",
    "            last_date = df.loc[df_len-i-1, '날짜']\n",
    "            if to_date(start_date) > to_date(last_date) :\n",
    "                drop_cnt += 1\n",
    "            else :\n",
    "                break\n",
    "        if drop_cnt > 0 :        \n",
    "            df = df[:-drop_cnt]\n",
    "    \n",
    "    # 정렬 및 컬럼명 변경 \n",
    "    if df.shape[0] != 0 :\n",
    "        df = df.sort_values(by='날짜')\n",
    "        df.rename(columns={'날짜': 'date', \n",
    "                           '종가': 'close', \n",
    "                           '전일비': 'diff', \n",
    "                           '시가': 'open', \n",
    "                           '고가': 'high',\n",
    "                           '저가': 'low', \n",
    "                           '거래량': 'volume'}, inplace=True)    \n",
    "    return df\n",
    "    \n",
    "def get_stock_data(comp_code) :\n",
    "    file_path = './data/' + comp_code + '.csv'\n",
    "    \n",
    "    if os.path.isfile(file_path) :\n",
    "        stock_data = pd.read_csv(file_path)\n",
    "        stock_data = stock_data[:-1]\n",
    "        date_last = stock_data.tail(1)['date'].to_string(index=False)\n",
    "        date_next = to_date(date_last) + datetime.timedelta(days=1)\n",
    "        date_next = date_next.strftime(\"%Y-%m-%d\")\n",
    "        new_data = get_stock_naver_data(comp_code, date_next)\n",
    "        if len(new_data) > 0 :\n",
    "            stock_data = stock_data.append(new_data, ignore_index=True)\n",
    "            stock_data.to_csv(file_path, index=False)\n",
    "    else :\n",
    "        stock_data = get_stock_naver_data(comp_code, '')\n",
    "        stock_data.to_csv(file_path, index=False)\n",
    "    return stock_data\n",
    "\n",
    "# matrix 데이터로 변경한다.\n",
    "def to_ndarray(cols_data) :\n",
    "    if isinstance(cols_data, Series):\n",
    "        return np.reshape(list(cols_data), (-1,1))\n",
    "    elif isinstance(cols_data, DataFrame):\n",
    "        return cols_data.as_matrix()\n",
    "\n",
    "# 컬럼을 스케일링을 시킨다.\n",
    "def get_scaled_cols(data, column_name) :\n",
    "    scale_data = to_ndarray(data[column_name])\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(scale_data), scaler;\n",
    "\n",
    "# 데이터를 스케일링 시킨다.\n",
    "def get_scaled_data(data) :\n",
    "    scaled_data = data.copy()\n",
    "    scaled_data = scaled_data[['close', 'open', 'high', 'low', 'volume']]\n",
    "    scaled_data = scaled_data[scaled_data['close']!=0]\n",
    "    scaled_data['close'], scaler_close = get_scaled_cols(scaled_data, 'close')\n",
    "    scaled_data['open'], _ = get_scaled_cols(scaled_data, 'open')\n",
    "    scaled_data['high'], _ = get_scaled_cols(scaled_data, 'high')\n",
    "    scaled_data['low'], _ = get_scaled_cols(scaled_data, 'low')\n",
    "    scaled_data['volume'], _ = get_scaled_cols(scaled_data, 'volume')\n",
    "    return scaled_data, scaler_close;\n",
    "\n",
    "# RNN을 위한 데이터로 만든다. \n",
    "def get_dataXY(data) :\n",
    "    x = to_ndarray(data)\n",
    "    y = to_ndarray(data['close'])\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    seq_length = params['seq_length']\n",
    "    y_len = len(y)\n",
    "    for i in range(0, y_len - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        _y = y[i + seq_length] # Next close price\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    dataX_last = [x[y_len-seq_length: y_len]]    \n",
    "    return dataX, dataY, y, dataX_last\n",
    "\n",
    "# train 및 test 데이터로 나눈다.\n",
    "def split_train_test(dataX, dataY, data, y) :\n",
    "    invest_count = params['invest_count']\n",
    "    seq_length = params['seq_length']\n",
    "    data_count = len(dataY);\n",
    "    train_size = int(data_count * params['train_percent'] / 100)\n",
    "    train_last = data_count-invest_count;\n",
    "    \n",
    "    trainX = np.array(dataX[0:train_size])\n",
    "    testX = np.array(dataX[train_size:train_last])\n",
    "    investX = np.array(dataX[train_last:data_count])\n",
    "    \n",
    "    trainY = np.array(dataY[0:train_size])\n",
    "    testY = np.array(dataY[train_size:train_last])\n",
    "    investY = np.array(dataY[train_last:data_count])\n",
    "    \n",
    "    trainCloses = np.array( y[seq_length-1:train_size+seq_length-1])\n",
    "    testCloses = np.array(dataY[train_size-1:train_last-1])\n",
    "    investCloses = np.array(dataY[train_last-1:data_count-1])\n",
    "    investRealCloses = np.array(data['close'][train_last-1+seq_length:data_count+seq_length].values)\n",
    "    #print(investRealCloses)\n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY, 'trainCloses': trainCloses,\n",
    "        'testX': testX, 'testY': testY, 'testCloses' : testCloses,\n",
    "        'investX': investX,'investY': investY, 'investCloses': investCloses, 'investRealCloses': investRealCloses\n",
    "    }\n",
    "\n",
    "# train, test데이터로 만든다.\n",
    "def get_train_test(data) :\n",
    "    scaled_data, scaler_close = get_scaled_data(data)\n",
    "    dataX, dataY, y, dataX_last = get_dataXY(scaled_data)\n",
    "    return split_train_test(dataX, dataY, data, y), scaler_close, dataX_last\n",
    "\n",
    "# 텐스플로우 변수관계 그래프롤 그린다.\n",
    "def draw_graph() :\n",
    "    seq_length = params['seq_length']\n",
    "    data_dim = params['data_dim']\n",
    "    hidden_dims = params['hidden_dims']\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "    X_closes = tf.placeholder(tf.float32, [None, 1])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "    output_keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    cells = []\n",
    "    for n in hidden_dims :\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_units=n, activation=tf.tanh)\n",
    "        dropout_cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=output_keep_prob)\n",
    "        cells.append(dropout_cell)\n",
    "    stacked_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(stacked_rnn_cell, X, dtype=tf.float32) \n",
    "    Y_pred = tf.contrib.layers.fully_connected(\n",
    "        outputs[:, -1], params['output_dim'], activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "    # cost/loss\n",
    "    loss = tf.reduce_sum(tf.square(1-(1+Y_pred-X_closes)/(1+Y-X_closes)))\n",
    "        \n",
    "    optimizer = tf.train.AdamOptimizer(params['learning_rate'])\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # RMSE\n",
    "    targets = tf.placeholder(tf.float32, [None, 1])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(1-(1+predictions-X_closes)/(1+targets-X_closes))))\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'output_keep_prob': output_keep_prob,\n",
    "        'train': train,\n",
    "        'loss' : loss,\n",
    "        'Y_pred': Y_pred,\n",
    "        'targets': targets,\n",
    "        'rmse' : rmse,\n",
    "        'predictions': predictions,\n",
    "        'X_closes' : X_closes\n",
    "    }\n",
    "\n",
    "def draw_plot(rmse_vals, test_predict, invest_predicts, comp_name, data_params) :\n",
    "    testY = data_params['testY']\n",
    "    investY = data_params['investY']\n",
    "    y = np.append(testY,investY)\n",
    "    predict =  np.append(test_predict, invest_predicts)\n",
    "    \n",
    "    mpl.rcParams['axes.unicode_minus'] = False\n",
    "    font_name = fm.FontProperties(fname=params['kor_font_path'], size=50).get_name()\n",
    "    plt.rc('font', family=font_name)\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot(rmse_vals, 'gold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Root Mean Square Error')\n",
    "    plt.title(comp_name)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(y, 'b')\n",
    "    plt.plot(predict, 'r')\n",
    "    plt.xlabel('Time Period')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.title(comp_name)\n",
    "    plt.show()\n",
    "\n",
    "def get_session_path(comp_code):\n",
    "    return \"./sessions/\" + comp_code + \".ckpt\"\n",
    "    \n",
    "def save_learning_image(sess, saver, graph_params, comp_code) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    X_closes = graph_params['X_closes']\n",
    "    train = graph_params['train']\n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    output_keep_prob = graph_params['output_keep_prob']\n",
    "    \n",
    "    tf.add_to_collection(\"X\", X)\n",
    "    tf.add_to_collection(\"X_closes\", X_closes)\n",
    "    tf.add_to_collection(\"Y\", Y)\n",
    "    tf.add_to_collection(\"train\", train)\n",
    "    tf.add_to_collection(\"Y_pred\", Y_pred)\n",
    "    tf.add_to_collection(\"output_keep_prob\", output_keep_prob)\n",
    "    saver.save(sess, get_session_path(comp_code))\n",
    "    \n",
    "# 학습을 시킨다.\n",
    "def let_training(graph_params, comp_code, data_params) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    output_keep_prob = graph_params['output_keep_prob']\n",
    "    train = graph_params['train']\n",
    "    loss = graph_params['loss']\n",
    "    trainX = data_params['trainX']\n",
    "    trainY = data_params['trainY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    trainCloses = data_params['trainCloses']\n",
    "    testCloses = data_params['testCloses']\n",
    "    dataLen = len(trainY) + len(testY)\n",
    "    \n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    targets = graph_params['targets']\n",
    "    rmse = graph_params['rmse']\n",
    "    predictions = graph_params['predictions']\n",
    "    X_closes = graph_params['X_closes']\n",
    "    loss_up_count = params['loss_up_count']\n",
    "    dropout_keep = params['dropout_keep']\n",
    "    iterations = params['iterations'] \n",
    "    rmse_max = params['rmse_max']\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    session_path = get_session_path(comp_code)\n",
    "    restored = False\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        \n",
    "        if os.path.isfile(session_path + '.meta'):\n",
    "            saver.restore(sess, session_path) \n",
    "            iterations[0] = 0\n",
    "            restored = True\n",
    "            \n",
    "        # Training step\n",
    "        min_rmse_val = 999999\n",
    "        less_cnt = 0\n",
    "        train_count = 0\n",
    "        rmse_vals = []\n",
    "        \n",
    "        for i in range(iterations[1]):\n",
    "            if i != 0 or not restored :\n",
    "                _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY, X_closes: trainCloses, output_keep_prob: dropout_keep})\n",
    "            test_predict = sess.run(Y_pred, feed_dict={X: testX, output_keep_prob: 1.0})\n",
    "            rmse_val = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict, X_closes: testCloses}) \n",
    "            rmse_vals.append(rmse_val)\n",
    "            \n",
    "            if i == 0 and restored:\n",
    "                max_test_predict, min_rmse_val, = test_predict, rmse_val\n",
    "                \n",
    "            if rmse_val < min_rmse_val :\n",
    "                save_learning_image(sess, saver, graph_params, comp_code)\n",
    "                less_cnt = 0\n",
    "                train_count = i;\n",
    "                max_test_predict, min_rmse_val, = test_predict, rmse_val\n",
    "            else :\n",
    "                less_cnt += 1\n",
    "            if i >= iterations[0] and less_cnt > loss_up_count and rmse_max > min_rmse_val:\n",
    "                break\n",
    "        #draw_plot(rmse_vals, max_test_predict, testY, comp_name) \n",
    "        return min_rmse_val, train_count, rmse_vals, max_test_predict\n",
    "\n",
    "\n",
    "# 그래프를 그리고 학습을 시킨다.    \n",
    "def let_leaning(comp_code, data_params):\n",
    "    graph_params = draw_graph()\n",
    "    return let_training(graph_params, comp_code, data_params)\n",
    "\n",
    "\n",
    "# 예측 값에 따라 매수 매도를 실행한다.    \n",
    "def let_invest_money(invest_predict, now_scaled_close, now_close, now_money, now_stock_cnt) :\n",
    "    seq_length = params['seq_length']\n",
    "    data_dim = params['data_dim']\n",
    "    fee_percent = params['fee_percent']\n",
    "    invest_min_percent = params['invest_min_percent']\n",
    "    \n",
    "    ratio = (invest_predict - now_scaled_close) /now_scaled_close * 100\n",
    "    \n",
    "    if ratio > invest_min_percent :\n",
    "        cnt = math.floor(now_money/now_close)\n",
    "        if cnt > 0 :\n",
    "            fee = now_close * fee_percent/100\n",
    "            now_money -= (now_close + fee) * cnt\n",
    "            now_stock_cnt += cnt\n",
    "    elif ratio < -invest_min_percent :\n",
    "        if now_stock_cnt > 0 :\n",
    "            now_money += to_money(now_close, now_stock_cnt)\n",
    "            now_stock_cnt = 0\n",
    "    return now_money, now_stock_cnt\n",
    "\n",
    "# 주식매도를 해서 돈으로 바꾼다.\n",
    "def to_money(now_stock_cnt, now_close) :\n",
    "    money = 0\n",
    "    if now_stock_cnt > 0 :\n",
    "        fee_percent = params['fee_percent'] \n",
    "        tax_percent = params['tax_percent']\n",
    "        \n",
    "        fee = now_close * fee_percent/100\n",
    "        tax = now_close * tax_percent/100\n",
    "        money = (now_close - (fee + tax)) * now_stock_cnt\n",
    "    return money\n",
    "    \n",
    "# 학습 후 모의 주식 거래를 한다.\n",
    "def let_invest(comp_code, train_cnt, dataX_last, data_params):\n",
    "    invest_count = params['invest_count']\n",
    "    invest_money = params['invest_money']\n",
    "    dropout_keep = params['dropout_keep']\n",
    "    \n",
    "    investX = data_params['investX']\n",
    "    investCloses = data_params['investCloses']\n",
    "    investRealCloses = data_params['investRealCloses']\n",
    "    investX = data_params['investX']\n",
    "    investY = data_params['investY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    testCloses = data_params['testCloses']\n",
    "    \n",
    "    now_stock_cnt = 0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        saver.restore(sess, get_session_path(comp_code)) \n",
    "        X = tf.get_collection('X')[0]\n",
    "        X_closes = tf.get_collection('X_closes')[0]\n",
    "        Y = tf.get_collection('Y')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "        Y_pred = tf.get_collection('Y_pred')[0]\n",
    "        output_keep_prob = tf.get_collection('output_keep_prob')[0]\n",
    "        \n",
    "        for i in range(int(train_cnt)):\n",
    "            sess.run(train, feed_dict={X: testX, Y: testY, X_closes: testCloses, \n",
    "                                       output_keep_prob: dropout_keep})\n",
    "        predicts = []\n",
    "        now_close = 0\n",
    "        for i in range(invest_count) :\n",
    "            invest_predicts = sess.run(Y_pred, feed_dict={X: investX[i:i+1], output_keep_prob: 1.0})\n",
    "            predicts.append(invest_predicts[0])\n",
    "            \n",
    "            invest_predict = invest_predicts[0][0];\n",
    "            now_scaled_close = investCloses[0][0]\n",
    "            now_close = investRealCloses[i]\n",
    "            #print(invest_predict, now_scaled_close, now_close)\n",
    "            invest_money, now_stock_cnt = let_invest_money(invest_predict, now_scaled_close, now_close,\n",
    "                                                           invest_money, now_stock_cnt)\n",
    "            for i in range(int(train_cnt/5)):\n",
    "                sess.run(train, feed_dict={X: investX[i:i+1], Y: investY[i:i+1], X_closes: investCloses[i:i+1], \n",
    "                                           output_keep_prob: dropout_keep})\n",
    "            #break\n",
    "        invest_money += to_money(now_stock_cnt, now_close)\n",
    "        #graph_params = {'X':X, 'X_closes':X_closes, 'Y':Y, 'train':train, \n",
    "        #                'Y_pred':Y_pred, 'output_keep_prob':output_keep_prob}\n",
    "        #save_learning_image(sess, saver, graph_params, comp_code)\n",
    "        \n",
    "        last_predict = sess.run(Y_pred, feed_dict={X: dataX_last, output_keep_prob: 1.0})\n",
    "    #print(now_money)\n",
    "    return invest_money, last_predict, predicts\n",
    "\n",
    "# 실제 가격을 가져온다.\n",
    "def get_real_money(data_params, scaler_close, last_predict) :\n",
    "    investRealCloses = data_params['investRealCloses'];\n",
    "    predict_money = scaler_close.inverse_transform(last_predict)\n",
    "    last_close_money = investRealCloses[len(investRealCloses)-1]\n",
    "    last_pred_money = predict_money[0][0]\n",
    "    return last_close_money, last_pred_money\n",
    "\n",
    "# 다음날 종가를 예측한다.\n",
    "def predict_next_close(comp_name) :\n",
    "    comp_code = get_comp_code(comp_name)\n",
    "    stock_data = get_stock_data(comp_code)\n",
    "    data_params, scaler_close, dataX_last = get_train_test(stock_data)\n",
    "    rmse_val, train_cnt, rmse_vals, test_predict  = let_leaning(comp_code, data_params)\n",
    "    last_money, last_predict, invest_predicts = let_invest(comp_code, train_cnt, dataX_last, data_params)\n",
    "    draw_plot(rmse_vals, test_predict, invest_predicts, comp_name, data_params)\n",
    "    last_close_money, last_pred_money = get_real_money(data_params, scaler_close, last_predict)\n",
    "    print(\"RMSE:\", rmse_val)\n",
    "    print(\"train_cnt:\", train_cnt)\n",
    "    if params['invest_count'] > 0 :\n",
    "        print(str(params['invest_count']) + \"회 모의투자 결과(100만원 투자):\", \"{:,.0f}\".format(last_money))\n",
    "    last_date = stock_data.tail(1)['date'].to_string(index=False)\n",
    "    print(\"마지막 종가(\" + last_date + \"):\", \"{:,.0f}\".format(last_close_money))\n",
    "    last_pred_ratio = (last_pred_money-last_close_money)/last_close_money * 100\n",
    "    last_pred_ratio = \"(\" + \"{:.2f}\".format(last_pred_ratio) + \"%)\"\n",
    "    print(\"예측 종가:\", \"{:,.0f}\".format( last_pred_money ), last_pred_ratio)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seq_length' : 5, # 시퀀스 갯수\n",
    "    'data_dim' : 5,    # 입력 데이터 갯수\n",
    "    'hidden_dims' : [128, 96, 64],  # 히든 레이어 갯수 \n",
    "    'dropout_keep' : 0.8, # dropout \n",
    "    'output_dim' : 1,  # 출력 데이터 갯수\n",
    "    'learning_rate' : 0.0001, \n",
    "    'iterations' : [1000, 10000],  # 최소, 최대 훈련 반복횟수\n",
    "    'rmse_max' : 0.02,\n",
    "    'train_percent' : 80.0, # 훈련 데이터 퍼센트\n",
    "    'loss_up_count' : 100, # early stopping\n",
    "    'invest_count' : 0,  # 투자 횟수\n",
    "    'invest_money' : 1000000, # 각 주식에 모의투자할 금액\n",
    "    'fee_percent' : 0.015, # 투자시 발생하는 수수료\n",
    "    'tax_percent' : 0.5,   # 매도시 발생하는 세금\n",
    "    'invest_min_percent' : 0.6, # 투자를 하는 최소 간격 퍼센트 \n",
    "    'kor_font_path' : 'C:\\\\WINDOWS\\\\Fonts\\\\H2GTRM.TTF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./sessions/063080.ckpt\n"
     ]
    }
   ],
   "source": [
    "#comp_names = [\"삼성중공업\",\"기아자동차\", \"게임빌\",\"루트로닉\", \"영진약품\", \"대아티아이\"]\n",
    "comp_names = [\"게임빌\",\"루트로닉\", \"영진약품\", \"대아티아이\"]\n",
    "for comp_name in comp_names :\n",
    "    predict_next_close(comp_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
