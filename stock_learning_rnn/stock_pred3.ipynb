{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_zip = zipfile.ZipFile('./Stock_Dataset(2017_07_06).zip')\n",
    "fantasy_zip.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /opt/venv/lib/python3.6/site-packages (1.1.0)\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/venv/lib/python3.6/site-packages (2.5.4)\n",
      "Requirement already satisfied: et-xmlfile in /opt/venv/lib/python3.6/site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: jdcal in /opt/venv/lib/python3.6/site-packages (from openpyxl) (1.4)\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 메소드 정의 \n",
    "# 상세 데이터를 가져온다.\n",
    "def get_stock_datail(comp_code) :\n",
    "    code = format(comp_code, \"06d\");\n",
    "    return pd.read_csv('./data/' + code + '.csv')\n",
    "\n",
    "# matrix 데이터로 변경한다.\n",
    "def to_ndarray(cols_data) :\n",
    "    if isinstance(cols_data, Series):\n",
    "        return np.reshape(list(cols_data), (-1,1))\n",
    "    elif isinstance(cols_data, DataFrame):\n",
    "        return cols_data.as_matrix()\n",
    "\n",
    "# 컬럼을 스케일링을 시킨다.\n",
    "def get_scaled_cols(data, column_name) :\n",
    "    scale_data = to_ndarray(data[column_name])\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(scale_data);\n",
    "\n",
    "# 데이터를 스케일링 시킨다.\n",
    "def get_scaled_data(data) :\n",
    "    scaled_data = data.copy()\n",
    "    scaled_data['Close'] = get_scaled_cols(scaled_data, 'Close')\n",
    "    scaled_data['Open'] = get_scaled_cols(scaled_data, 'Open')\n",
    "    scaled_data['High'] = get_scaled_cols(scaled_data, 'High')\n",
    "    scaled_data['Low'] = get_scaled_cols(scaled_data, 'Low')\n",
    "    scaled_data['Volume'] = get_scaled_cols(scaled_data, 'Volume')\n",
    "    return scaled_data;\n",
    "\n",
    "# RNN을 위한 데이터로 만든다. \n",
    "def get_dataXY(data, train_params) :\n",
    "    x = to_ndarray(data[['Open', 'High', 'Low', 'Volume', 'Close']])\n",
    "    y = to_ndarray(data['Close'])\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    seq_length = train_params['seq_length']\n",
    "    for i in range(0, len(y) - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        _y = y[i + seq_length] # Next close price\n",
    "        #print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return dataX, dataY, y\n",
    "\n",
    "# train 및 test 데이터로 나눈다.\n",
    "def split_train_test(dataX, dataY, train_params, data, y) :\n",
    "    invest_count = train_params['invest_count']\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_count = len(dataY);\n",
    "    train_size = int(data_count * train_params['train_percent'] / 100)\n",
    "    train_last = data_count-invest_count;\n",
    "    \n",
    "    trainX = np.array(dataX[0:train_size])\n",
    "    testX = np.array(dataX[train_size:train_last])\n",
    "    investX = np.array(dataX[train_last:data_count])\n",
    "    \n",
    "    trainY = np.array(dataY[0:train_size])\n",
    "    testY = np.array(dataY[train_size:train_last])\n",
    "    investY = np.array(dataY[train_last:data_count])\n",
    "    \n",
    "    trainCloses = np.array( y[seq_length-1:train_size+seq_length-1])\n",
    "    testCloses = np.array(dataY[train_size-1:train_last-1])\n",
    "    investCloses = np.array(dataY[train_last-1:data_count-1])\n",
    "    investRealCloses = np.array(data['Close'][train_last-1+seq_length:data_count-1+seq_length].values)\n",
    "    \n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY, 'trainCloses': trainCloses,\n",
    "        'testX': testX, 'testY': testY, 'testCloses' : testCloses,\n",
    "        'investX': investX,'investY': investY, 'investCloses': investCloses, 'investRealCloses': investRealCloses\n",
    "    }\n",
    "\n",
    "# train, test데이터로 만든다.\n",
    "def get_train_test(data, train_params) :\n",
    "    scaled_data = get_scaled_data(data)\n",
    "    dataX, dataY, y = get_dataXY(scaled_data, train_params)\n",
    "    return split_train_test(dataX, dataY, train_params, data, y)\n",
    "\n",
    "# 텐스플로우 변수관계 그래프롤 그린다.\n",
    "def draw_graph(train_params) :\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    hidden_dims = train_params['hidden_dims']\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "    X_closes = tf.placeholder(tf.float32, [None, 1])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "    input_keep_prob = tf.placeholder(tf.float32)\n",
    "    output_keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n, activation=tf.tanh) for n in hidden_dims]\n",
    "    stacked_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(stacked_rnn_cell, X, dtype=tf.float32) \n",
    "    \n",
    "#     cell = tf.contrib.rnn.BasicLSTMCell(num_units=train_params['hidden_dim'], state_is_tuple=True, activation=tf.tanh)\n",
    "#     dropout = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=input_keep_prob, input_keep_prob=output_keep_prob)\n",
    "#     cell = tf.nn.rnn_cell.MultiRNNCell([cell, dropout] * num_layers, state_is_tuple=True)\n",
    "#     outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32) \n",
    "    \n",
    "    Y_pred = tf.contrib.layers.fully_connected(\n",
    "        outputs[:, -1], train_params['output_dim'], activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "    # cost/loss\n",
    "    loss = tf.reduce_sum(tf.square(Y_pred - Y)  + tf.maximum(-tf.sign(X_closes-Y) * tf.sign(X_closes-Y_pred), 0))  # sum of the squares\n",
    "    #loss = tf.reduce_sum(tf.maximum(-tf.sign(X_closes-Y) * tf.sign(X_closes-Y_pred), 0))\n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(train_params['learning_rate'])\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # RMSE\n",
    "    targets = tf.placeholder(tf.float32, [None, 1])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "    direction_error = tf.reduce_mean(tf.maximum(-tf.sign(X_closes-targets) * tf.sign(X_closes-predictions), 0))\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'input_keep_prob': input_keep_prob,\n",
    "        'output_keep_prob': output_keep_prob,\n",
    "        'train': train,\n",
    "        'loss' : loss,\n",
    "        'Y_pred': Y_pred,\n",
    "        'targets': targets,\n",
    "        'rmse' : rmse,\n",
    "        'predictions': predictions,\n",
    "        'X_closes' : X_closes,\n",
    "        'direction_error' : direction_error\n",
    "    }\n",
    "\n",
    "# 학습을 시킨다.\n",
    "def let_training(data_params, train_params, graph_params, comp_code) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    input_keep_prob = graph_params['input_keep_prob']\n",
    "    output_keep_prob = graph_params['output_keep_prob']\n",
    "    train = graph_params['train']\n",
    "    loss = graph_params['loss']\n",
    "    trainX = data_params['trainX']\n",
    "    trainY = data_params['trainY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    trainCloses = data_params['trainCloses']\n",
    "    testCloses = data_params['testCloses']\n",
    "    \n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    targets = graph_params['targets']\n",
    "    rmse = graph_params['rmse']\n",
    "    predictions = graph_params['predictions']\n",
    "    X_closes = graph_params['X_closes']\n",
    "    direction_error = graph_params['direction_error']\n",
    "    loss_up_count = train_params['loss_up_count']\n",
    "    dropout_keep = train_params['dropout_keep']\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # Training step\n",
    "        min_rmse_val = 999999\n",
    "        min_direction_error_val = 999999\n",
    "        less_cnt = 0\n",
    "        train_count = 0\n",
    "        for i in range(train_params['iterations']):\n",
    "            _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY, X_closes: trainCloses, input_keep_prob: dropout_keep, output_keep_prob: dropout_keep})\n",
    "            if i % 100 == 0 :\n",
    "                test_predict = sess.run(Y_pred, feed_dict={X: testX, input_keep_prob: 1.0, output_keep_prob: 1.0})\n",
    "                rmse_val, direction_error_val = sess.run([rmse,  direction_error], \n",
    "                                                feed_dict={targets: testY, predictions: test_predict, X_closes: testCloses}) \n",
    "                print(step_loss, rmse_val, direction_error_val)\n",
    "                #if rmse_val < min_rmse_val :\n",
    "                if direction_error_val + rmse_val < min_direction_error_val + min_rmse_val :\n",
    "                    tf.add_to_collection(\"X\", X)\n",
    "                    tf.add_to_collection(\"X_closes\", X_closes)\n",
    "                    tf.add_to_collection(\"Y\", Y)\n",
    "                    tf.add_to_collection(\"train\", train)\n",
    "                    tf.add_to_collection(\"Y_pred\", Y_pred)\n",
    "                    tf.add_to_collection(\"input_keep_prob\", input_keep_prob)\n",
    "                    tf.add_to_collection(\"output_keep_prob\", output_keep_prob)\n",
    "                    saver.save(sess, \"./sessions/\" + str(comp_code) + \".ckpt\")\n",
    "                    less_cnt = 0\n",
    "                    train_count = i;\n",
    "                    max_test_predict, min_rmse_val, min_direction_error_val = test_predict, rmse_val, direction_error_val\n",
    "                else :\n",
    "                    less_cnt += 1\n",
    "                if less_cnt > loss_up_count :\n",
    "                    break\n",
    "        \n",
    "        return max_test_predict, min_rmse_val, min_direction_error_val, train_count \n",
    "\n",
    "# 그래프를 그리고 학습을 시킨다.    \n",
    "def let_leaning(data_params, train_params, comp_code):\n",
    "    graph_params = draw_graph(train_params)\n",
    "    return let_training(data_params, train_params, graph_params, comp_code)\n",
    "\n",
    "def to_dataFrame(data, columns) :\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# excel로 저장한다.\n",
    "def save_excel(df_data, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    df_data.to_excel(writer,'Sheet1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "# 예측 값에 따라 매수 매도를 실행한다.    \n",
    "def let_invest_money(invest_predict, now_scaled_close, now_close, train_params, now_money, now_stock_cnt) :\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    pie_percent = train_params['pie_percent']\n",
    "    invest_min_percent = train_params['invest_min_percent']\n",
    "    \n",
    "    ratio = (invest_predict - now_scaled_close) /now_scaled_close * 100\n",
    "    \n",
    "    if ratio > invest_min_percent :\n",
    "        cnt = math.floor(now_money/now_close)\n",
    "        if cnt > 0 :\n",
    "            pie = now_close * pie_percent/100\n",
    "            now_money -= (now_close + pie) * cnt\n",
    "            now_stock_cnt += cnt\n",
    "    elif ratio < -invest_min_percent :\n",
    "        if now_stock_cnt > 0 :\n",
    "            now_money += to_money(now_close, now_stock_cnt, train_params)\n",
    "            now_stock_cnt = 0\n",
    "    #print(now_money, now_stock_cnt, now_scaled_close, invest_predict, data_params['testY'])\n",
    "    return now_money, now_stock_cnt\n",
    "\n",
    "# 주식매도를 해서 돈으로 바꾼다.\n",
    "def to_money(now_stock_cnt, now_close, train_params) :\n",
    "    money = 0\n",
    "    if now_stock_cnt > 0 :\n",
    "        pie_percent = train_params['pie_percent'] \n",
    "        tax_percent = train_params['tax_percent']\n",
    "        \n",
    "        pie = now_close * pie_percent/100\n",
    "        tax = now_close * tax_percent/100\n",
    "        money = (now_close - (pie + tax)) * now_stock_cnt\n",
    "    return money\n",
    "    \n",
    "# 학습 후 모의 주식 거래를 한다.\n",
    "def let_invest(row, train_params, data_params, train_cnt):\n",
    "    comp_code = row['종목코드']\n",
    "    invest_count = train_params['invest_count']\n",
    "    invest_money = train_params['invest_money']\n",
    "    dropout_keep = train_params['dropout_keep']\n",
    "    \n",
    "    investX = data_params['investX']\n",
    "    investCloses = data_params['investCloses']\n",
    "    investRealCloses = data_params['investRealCloses']\n",
    "    investX = data_params['investX']\n",
    "    investY = data_params['investY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    testCloses = data_params['testCloses']\n",
    "    #print(investRealCloses)\n",
    "    \n",
    "    now_stock_cnt = 0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        saver.restore(sess, \"./sessions/\" + str(comp_code) + \".ckpt\") \n",
    "        X = tf.get_collection('X')[0]\n",
    "        X_closes = tf.get_collection('X_closes')[0]\n",
    "        Y = tf.get_collection('Y')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "        Y_pred = tf.get_collection('Y_pred')[0]\n",
    "        input_keep_prob = tf.get_collection('input_keep_prob')[0]\n",
    "        output_keep_prob = tf.get_collection('output_keep_prob')[0]\n",
    "        \n",
    "        for i in range(int(train_cnt/10)):\n",
    "            sess.run(train, feed_dict={X: testX, Y: testY, X_closes: testCloses, input_keep_prob: dropout_keep, output_keep_prob: dropout_keep})\n",
    "        \n",
    "        for i in range(invest_count) :\n",
    "            np.array([1, 2, 3], ndmin=2)\n",
    "            invest_predicts = sess.run(Y_pred, feed_dict={X: investX[i:i+1], input_keep_prob: 1.0, output_keep_prob: 1.0})\n",
    "            \n",
    "            invest_predict = invest_predicts[0][0];\n",
    "            now_scaled_close = investCloses[0][0]\n",
    "            now_close = investRealCloses[i]\n",
    "            #print(invest_predict, now_scaled_close, now_close)\n",
    "            invest_money, now_stock_cnt = let_invest_money(invest_predict, now_scaled_close, now_close,\n",
    "                                                           train_params, invest_money, now_stock_cnt)\n",
    "            for i in range(int(train_cnt/100)):\n",
    "                sess.run(train, feed_dict={X: investX[i:i+1], Y: investY[i:i+1], X_closes: investCloses[i:i+1], input_keep_prob: dropout_keep, output_keep_prob: dropout_keep})\n",
    "            #break\n",
    "        invest_money += to_money(now_stock_cnt, now_close, train_params)\n",
    "    #print(now_money)\n",
    "    return invest_money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 정의 \n",
    "# train Parameters\n",
    "train_params = {\n",
    "    'seq_length' : 7, # 시퀀스 갯수\n",
    "    'data_dim' : 5,    # 입력 데이터 갯수\n",
    "    'hidden_dims' : [64, 32],  # 히든 레이어 갯수 \n",
    "    'output_dim' : 1,  # 출력 데이터 갯수\n",
    "    'learning_rate' : 0.001, \n",
    "    'iterations' : 100000,  # 최대 훈련 반복횟수\n",
    "    'train_percent' : 70.0, # 훈련 데이터 퍼센트\n",
    "    'dropout_keep' : 1.0, # dropout \n",
    "    'loss_up_count' : 10, # early stopping\n",
    "    'invest_corp_count' : 100, # 투자하는 주식회사 갯수\n",
    "    'invest_count' : 20,  # 투자 횟수\n",
    "    'invest_money' : 1000000, # 각 주식에 모의투자할 금액\n",
    "    'pie_percent' : 0.015, # 투자시 발생하는 수수료\n",
    "    'tax_percent' : 0.5,   # 매도시 발생하는 세금\n",
    "    'invest_min_percent' : 0.6 # 투자를 하는 최소 간격 퍼센트 \n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식회사 데이터\n",
    "corporations = pd.read_excel('./corporations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_corps = corporations.query(\"상장일<'2005-01-01'  \")[['회사명', '종목코드']]\n",
    "#print(stock_corps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937.55597 0.559256 0.4401806\n",
      "826.35864 0.027167534 0.47291195\n",
      "813.3366 0.025264803 0.4717833\n",
      "814.328 0.024852926 0.4582393\n",
      "820.31903 0.025661008 0.44582394\n",
      "815.30945 0.026768016 0.44130924\n",
      "809.29944 0.027600152 0.43792325\n",
      "806.28894 0.028002052 0.43679458\n",
      "802.2778 0.028079856 0.43792325\n",
      "805.26544 0.02814223 0.4356659\n",
      "802.25104 0.029009305 0.44243792\n",
      "797.23224 0.03388616 0.4322799\n",
      "784.20685 0.050660748 0.4288939\n",
      "781.177 0.05026709 0.43115124\n",
      "781.1587 0.024621189 0.45485327\n",
      "772.1496 0.021162359 0.4604966\n",
      "781.1414 0.020629253 0.4503386\n",
      "786.13477 0.020984288 0.48307\n",
      "785.1286 0.019305209 0.4819413\n",
      "764.12354 0.01715188 0.4537246\n",
      "784.11725 0.01733558 0.48871332\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/1460.ckpt\n",
      "code name rmse direction_error invest_result\n",
      "1460 BYC 0.02814223 0.4356659 989785.6\n",
      "1002.28015 0.52672076 0.46162528\n",
      "914.1613 0.034781232 0.45146728\n",
      "933.14825 0.044182003 0.43679458\n",
      "939.14514 0.052300885 0.43905193\n",
      "938.14246 0.053182807 0.44130924\n",
      "935.1393 0.052471463 0.43792325\n",
      "935.1355 0.05168633 0.4356659\n",
      "926.13104 0.051524896 0.43792325\n",
      "920.1254 0.0537639 0.43792325\n",
      "917.11804 0.062966906 0.4401806\n",
      "920.1092 0.08428981 0.45146728\n",
      "930.1012 0.108780004 0.4537246\n",
      "939.0954 0.09610429 0.4401806\n",
      "945.08887 0.074199304 0.44582394\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/79160.ckpt\n",
      "79160 CJ CGV 0.044182003 0.43679458 976960.18\n",
      "1737.849 0.91097975 0.48645598\n",
      "961.39966 0.035702553 0.47065464\n",
      "962.3374 0.031531967 0.4650113\n",
      "961.3198 0.03212654 0.46726862\n",
      "953.30273 0.03269412 0.46388263\n",
      "957.28516 0.03306775 0.46952596\n",
      "957.2664 0.033184 0.4683973\n",
      "963.24585 0.033051223 0.46726862\n",
      "963.2228 0.03272303 0.46952596\n",
      "962.1962 0.03227508 0.4683973\n",
      "966.1647 0.031807087 0.4717833\n",
      "960.12463 0.03149203 0.47291195\n",
      "965.0673 0.031685047 0.4717833\n",
      "961.9741 0.03185 0.4751693\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/5830.ckpt\n",
      "5830 DB손해보험 0.031531967 0.4650113 950177.36\n",
      "992.7081 0.17721048 0.4537246\n",
      "961.4116 0.037392188 0.4356659\n",
      "964.37415 0.035824593 0.43679458\n",
      "963.3221 0.033444736 0.4288939\n",
      "959.25354 0.06609745 0.42437923\n",
      "952.2102 0.056690942 0.4435666\n",
      "969.18207 0.03094537 0.44130924\n",
      "953.1761 0.028771253 0.46275395\n",
      "967.15894 0.03028873 0.45598194\n",
      "968.1532 0.030001963 0.4571106\n",
      "964.14984 0.030076744 0.46275395\n",
      "983.1454 0.029366894 0.45598194\n",
      "976.1445 0.029470664 0.47404063\n",
      "992.13947 0.028653856 0.4571106\n",
      "986.1357 0.026673602 0.46613994\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/69730.ckpt\n",
      "69730 DSR제강 0.033444736 0.4288939 1000000\n",
      "1247.2906 0.13708763 0.46613994\n",
      "1000.8351 0.011604276 0.4503386\n",
      "1013.46216 0.011448087 0.4751693\n",
      "1009.81354 0.010627722 0.4650113\n",
      "998.8061 0.009200917 0.46162528\n",
      "978.5646 0.008824193 0.4582393\n",
      "980.3519 0.008494905 0.45485327\n",
      "970.237 0.00848963 0.44695258\n",
      "968.17914 0.008078068 0.45485327\n",
      "965.1509 0.007984393 0.44243792\n",
      "1001.2237 0.007939727 0.4582393\n",
      "977.12604 0.007770599 0.44582394\n",
      "969.12134 0.0077187517 0.45259595\n",
      "968.1111 0.007620819 0.45598194\n",
      "971.1817 0.009049616 0.47968397\n",
      "957.0981 0.007489889 0.45598194\n",
      "959.0898 0.0073910677 0.45259595\n",
      "1005.27246 0.012200299 0.45146728\n",
      "960.07947 0.0072994544 0.45146728\n",
      "966.0718 0.0072010797 0.45485327\n",
      "971.0642 0.007110704 0.4571106\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/9440.ckpt\n",
      "9440 KC그린홀딩스 0.007984393 0.44243792 989160.64\n",
      "1388.1187 0.46722338 0.44243792\n",
      "913.5436 0.023295552 0.43792325\n",
      "916.4707 0.021995135 0.44130924\n",
      "917.3994 0.0215654 0.4322799\n",
      "918.31506 0.021138214 0.43115124\n",
      "918.20807 0.020618005 0.4322799\n",
      "914.0427 0.019718818 0.41647854\n",
      "925.7587 0.01816985 0.41647854\n",
      "926.4701 0.016500302 0.40293455\n",
      "917.3397 0.01585101 0.40970653\n",
      "911.22614 0.0153076025 0.41760722\n",
      "923.0988 0.014609852 0.42325056\n",
      "918.0167 0.015282557 0.4322799\n",
      "893.9081 0.013435629 0.4255079\n",
      "894.859 0.013005712 0.42212188\n",
      "975.11163 0.012845997 0.43002257\n",
      "888.7715 0.012439805 0.42437923\n",
      "893.7742 0.014299424 0.44469526\n",
      "873.73755 0.01218756 0.42325056\n",
      "894.7024 0.011958115 0.41422123\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/1940.ckpt\n",
      "1940 KISCO홀딩스 0.016500302 0.40293455 938746.7900000002\n",
      "961.53845 0.08278655 0.4582393\n",
      "952.8084 0.009011894 0.47065464\n",
      "933.79816 0.008075789 0.45485327\n",
      "939.65796 0.008319044 0.45146728\n",
      "939.5896 0.008005253 0.45146728\n",
      "949.5677 0.008348169 0.4604966\n",
      "957.5793 0.008089746 0.46275395\n",
      "927.5539 0.007905041 0.4582393\n",
      "962.5193 0.008815554 0.4537246\n",
      "947.5032 0.008584069 0.45598194\n",
      "947.47754 0.00856345 0.4503386\n",
      "947.40796 0.007776804 0.45259595\n",
      "952.2715 0.00784934 0.4503386\n",
      "950.21936 0.0080963075 0.44582394\n",
      "934.1426 0.007691886 0.4582393\n",
      "950.14404 0.0073097083 0.4604966\n",
      "942.13007 0.0070419875 0.46162528\n",
      "941.1282 0.00689973 0.45485327\n",
      "942.122 0.006775345 0.44808125\n",
      "935.1175 0.0066999355 0.44920993\n",
      "920.88696 0.0072220312 0.4683973\n",
      "955.7185 0.0063598095 0.4537246\n",
      "927.72046 0.008205238 0.49097064\n",
      "948.64526 0.007048122 0.46388263\n",
      "929.6221 0.0068222084 0.4717833\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/23150.ckpt\n",
      "23150 MH에탄올 0.0080963075 0.44582394 1000000\n",
      "1280.4525 0.12801255 0.45146728\n",
      "824.8544 0.01981902 0.43002257\n",
      "827.3085 0.024615867 0.4503386\n",
      "833.0826 0.026178129 0.44920993\n",
      "839.8207 0.025470164 0.44920993\n",
      "844.4622 0.023681542 0.44808125\n",
      "823.9075 0.021976145 0.4334086\n",
      "827.5203 0.022326633 0.44469526\n",
      "820.42334 0.019809281 0.44243792\n",
      "827.36646 0.017272294 0.4356659\n",
      "818.32874 0.0151711395 0.41760722\n",
      "811.3032 0.013485632 0.4085779\n",
      "799.28625 0.012202248 0.4040632\n",
      "798.27484 0.011267852 0.40970653\n",
      "840.2912 0.010757922 0.4153499\n",
      "802.26056 0.0101072835 0.41647854\n",
      "811.25586 0.009748909 0.41760722\n",
      "807.25073 0.009406344 0.42099324\n",
      "803.2471 0.009159282 0.4187359\n",
      "808.24286 0.008947812 0.42663658\n",
      "802.24316 0.008878847 0.42212188\n",
      "806.2366 0.008680549 0.42776525\n",
      "804.233 0.008579391 0.43002257\n",
      "808.2292 0.008499863 0.4255079\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/34310.ckpt\n",
      "34310 NICE 0.012202248 0.4040632 959711.47\n",
      "1097.2958 0.24697623 0.4435666\n",
      "949.47363 0.013963519 0.43679458\n",
      "942.4105 0.013811326 0.4356659\n",
      "935.33826 0.013578834 0.4356659\n",
      "929.21344 0.01323958 0.4334086\n",
      "913.9571 0.012571367 0.43679458\n",
      "901.775 0.011823791 0.43453723\n",
      "912.6743 0.011330609 0.44243792\n",
      "910.5805 0.010958158 0.44808125\n",
      "932.5205 0.010538199 0.44695258\n",
      "923.4829 0.010416549 0.4582393\n",
      "935.4608 0.01044694 0.4604966\n",
      "942.44165 0.010351739 0.46613994\n",
      "920.4186 0.009630951 0.4751693\n",
      "909.41406 0.009262176 0.46952596\n",
      "929.3889 0.009162255 0.46275395\n",
      "936.4546 0.011250913 0.4356659\n",
      "931.36884 0.0087975105 0.46275395\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/36530.ckpt\n",
      "36530 S&T홀딩스 0.011823791 0.43453723 1000000\n",
      "1241.9935 0.6050347 0.4582393\n",
      "928.09607 0.038030908 0.45259595\n",
      "936.0258 0.037121158 0.45485327\n",
      "921.9652 0.036909558 0.45259595\n",
      "925.8971 0.036781684 0.4537246\n",
      "926.8125 0.0366642 0.44695258\n",
      "930.683 0.03782888 0.44920993\n",
      "936.4451 0.044346135 0.4604966\n",
      "933.21484 0.031503163 0.4503386\n",
      "942.09155 0.028011609 0.45936796\n",
      "937.9776 0.025586762 0.45598194\n",
      "922.8797 0.024961904 0.4582393\n",
      "943.84033 0.022836527 0.44920993\n",
      "929.9309 0.026851634 0.47065464\n",
      "903.7294 0.02406661 0.45259595\n",
      "892.704 0.024207445 0.44808125\n",
      "899.69714 0.02386503 0.44695258\n",
      "880.6811 0.023619264 0.4288939\n",
      "872.6678 0.023166887 0.4288939\n",
      "863.6664 0.022404213 0.44130924\n",
      "851.6554 0.022732012 0.43115124\n",
      "853.6476 0.02237484 0.42776525\n",
      "842.6414 0.022055287 0.4255079\n",
      "870.65515 0.02241254 0.4334086\n",
      "837.63666 0.022069326 0.43792325\n",
      "841.63306 0.021912055 0.4334086\n",
      "848.6304 0.021812031 0.4288939\n",
      "935.7602 0.033813134 0.4582393\n",
      "832.6286 0.022059187 0.42776525\n",
      "839.62646 0.021973355 0.42212188\n",
      "844.62476 0.021931717 0.42099324\n",
      "843.62317 0.021915376 0.41986457\n",
      "815.6343 0.022131773 0.41647854\n",
      "830.6224 0.022108475 0.42212188\n",
      "830.6211 0.022067854 0.41986457\n",
      "830.6199 0.022031114 0.41647854\n",
      "826.6187 0.022111114 0.42776525\n",
      "820.6195 0.022308048 0.41986457\n",
      "825.6183 0.022137541 0.41647854\n",
      "824.6173 0.022078747 0.41647854\n",
      "829.6164 0.022035057 0.42099324\n",
      "827.61896 0.023029575 0.4356659\n",
      "825.61597 0.022130664 0.41647854\n",
      "824.6151 0.022070862 0.4187359\n",
      "818.6144 0.022022922 0.42099324\n",
      "808.616 0.021951359 0.4108352\n",
      "819.61426 0.022120934 0.42212188\n",
      "819.61346 0.022053625 0.42099324\n",
      "818.61273 0.022006912 0.42099324\n",
      "827.6173 0.021918647 0.40970653\n",
      "808.6128 0.022127056 0.42325056\n",
      "813.61206 0.02205099 0.42212188\n",
      "817.6115 0.022004476 0.4187359\n",
      "938.2711 0.026497899 0.4717833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802.6113 0.022086253 0.42776525\n",
      "804.61084 0.022053802 0.42437923\n",
      "800.61017 0.02201165 0.42437923\n",
      "961.9425 0.03616518 0.4582393\n",
      "810.6103 0.022141466 0.4255079\n",
      "806.6096 0.022083238 0.42325056\n",
      "806.6091 0.022037687 0.42099324\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/17670.ckpt\n",
      "17670 SK텔레콤 0.021918647 0.40970653 1034622.9500000001\n",
      "1101.0189 0.50930107 0.4650113\n",
      "928.7897 0.030579673 0.41986457\n",
      "924.7593 0.032352064 0.41986457\n",
      "926.7223 0.034024622 0.42776525\n",
      "927.66504 0.036100958 0.4322799\n",
      "925.5697 0.06732199 0.4503386\n",
      "941.4974 0.077274434 0.45259595\n",
      "934.4302 0.054452673 0.4582393\n",
      "935.3881 0.046420373 0.45259595\n",
      "946.36285 0.044024102 0.44920993\n",
      "968.3466 0.044707343 0.4503386\n",
      "978.3337 0.04701366 0.44808125\n",
      "964.3227 0.050894804 0.44920993\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/12200.ckpt\n",
      "12200 계양전기 0.030579673 0.41986457 973233.341\n",
      "907.2236 0.022807626 0.38487583\n",
      "864.194 0.01840108 0.47291195\n",
      "868.8567 0.016152976 0.4717833\n",
      "871.32074 0.0136688985 0.46952596\n",
      "866.1239 0.012671064 0.4650113\n",
      "840.9653 0.011132842 0.46726862\n",
      "827.80676 0.009054004 0.46275395\n",
      "835.7223 0.007652315 0.45485327\n",
      "823.6668 0.006878164 0.45936796\n",
      "825.629 0.00623651 0.44695258\n",
      "837.60425 0.0058352607 0.44920993\n",
      "800.5969 0.005793005 0.4503386\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/1290.ckpt\n",
      "1290 골든브릿지증권 0.022807626 0.38487583 1000000\n",
      "1515.7268 0.3711369 0.43115124\n",
      "954.8496 0.025557142 0.45146728\n",
      "947.68604 0.024203358 0.43679458\n",
      "942.62915 0.023817575 0.4401806\n",
      "947.5645 0.023470135 0.4334086\n",
      "941.4866 0.02310679 0.43002257\n",
      "937.3865 0.022666274 0.4288939\n",
      "939.2356 0.02201725 0.43002257\n",
      "962.8803 0.020518215 0.43115124\n",
      "990.6041 0.018806672 0.42212188\n",
      "982.50525 0.018246943 0.4288939\n",
      "990.409 0.017766206 0.4255079\n",
      "985.3105 0.017173158 0.41986457\n",
      "982.219 0.016626773 0.40519187\n",
      "969.1883 0.016218085 0.4085779\n",
      "981.0471 0.015656633 0.4040632\n",
      "964.00665 0.015372723 0.41196388\n",
      "962.95654 0.015023164 0.39954853\n",
      "931.9227 0.014767367 0.40293455\n",
      "930.9146 0.01468557 0.4006772\n",
      "916.89453 0.014540495 0.4006772\n",
      "903.87976 0.014426206 0.4006772\n",
      "897.8678 0.0143362805 0.40293455\n",
      "901.8656 0.01435849 0.4187359\n",
      "886.85614 0.014255158 0.4085779\n",
      "871.84863 0.014208089 0.40632054\n",
      "862.8423 0.014172404 0.40519187\n",
      "884.84314 0.01416088 0.40744922\n",
      "865.83673 0.014145438 0.40970653\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/24110.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 주식 종목들을 가져와서 학습을 시킨다.\n",
    "comp_rmses = []\n",
    "for idx, row in stock_corps.iterrows():\n",
    "    comp_code = row['종목코드']\n",
    "    data = get_stock_datail(comp_code)\n",
    "    data_params = get_train_test(data, train_params)\n",
    "    _, rmse_val, direction_error_val, train_cnt = let_leaning(data_params, train_params, comp_code)\n",
    "    \n",
    "    now_money = let_invest(row, train_params, data_params, train_cnt)\n",
    "    if idx == 0 :\n",
    "        print('code', 'name', 'rmse', 'direction_error', 'invest_result')\n",
    "    print(comp_code, row['회사명'], rmse_val, direction_error_val, now_money)\n",
    "    comp_rmses.append([comp_code, row['회사명'], rmse_val, direction_error_val, now_money])\n",
    "    #break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀파일로 저장한다.\n",
    "df_comp_rmses = pd.DataFrame(comp_rmses, columns=['code', 'name', 'rmse', 'direction_error', 'invest_result'])    \n",
    "#df_comp_rmses = df_comp_rmses.sort_values('invest_result', ascending=False)\n",
    "save_excel(df_comp_rmses, 'invest_result2.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
