{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_zip = zipfile.ZipFile('./Stock_Dataset(2017_07_06).zip')\n",
    "fantasy_zip.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Using cached https://files.pythonhosted.org/packages/07/e6/e95c4eec6221bfd8528bcc4ea252a850bffcc4be88ebc367e23a1a84b0bb/xlrd-1.1.0-py2.py3-none-any.whl\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "Collecting jdcal (from openpyxl)\n",
      "  Using cached https://files.pythonhosted.org/packages/a0/38/dcf83532480f25284f3ef13f8ed63e03c58a65c9d3ba2a6a894ed9497207/jdcal-1.4-py2.py3-none-any.whl\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: et-xmlfile, jdcal, openpyxl\n",
      "Successfully installed et-xmlfile-1.0.1 jdcal-1.4 openpyxl-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 메소드 정의 \n",
    "# 상세 데이터를 가져온다.\n",
    "def get_stock_datail(comp_code) :\n",
    "    code = format(comp_code, \"06d\");\n",
    "    return pd.read_csv('./data/' + code + '.csv')\n",
    "\n",
    "# matrix 데이터로 변경한다.\n",
    "def to_ndarray(cols_data) :\n",
    "    if isinstance(cols_data, Series):\n",
    "        return np.reshape(list(cols_data), (-1,1))\n",
    "    elif isinstance(cols_data, DataFrame):\n",
    "        return cols_data.as_matrix()\n",
    "\n",
    "# 컬럼을 스케일링을 시킨다.\n",
    "def get_scaled_cols(data, column_name) :\n",
    "    scale_data = to_ndarray(data[column_name])\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(scale_data);\n",
    "\n",
    "# 데이터를 스케일링 시킨다.\n",
    "def get_scaled_data(data) :\n",
    "    scaled_data = data.copy()\n",
    "    scaled_data['Close'] = get_scaled_cols(scaled_data, 'Close')\n",
    "    scaled_data['Open'] = get_scaled_cols(scaled_data, 'Open')\n",
    "    scaled_data['High'] = get_scaled_cols(scaled_data, 'High')\n",
    "    scaled_data['Low'] = get_scaled_cols(scaled_data, 'Low')\n",
    "    scaled_data['Volume'] = get_scaled_cols(scaled_data, 'Volume')\n",
    "    return scaled_data;\n",
    "\n",
    "# RNN을 위한 데이터로 만든다. \n",
    "def get_dataXY(data, train_params) :\n",
    "    x = to_ndarray(data[['Open', 'High', 'Low', 'Volume', 'Close']])\n",
    "    y = to_ndarray(data['Close'])\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    seq_length = train_params['seq_length']\n",
    "    for i in range(0, len(y) - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        _y = y[i + seq_length] # Next close price\n",
    "        #print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return dataX, dataY, y\n",
    "\n",
    "# train 및 test 데이터로 나눈다.\n",
    "def split_train_test(dataX, dataY, train_params, data, y) :\n",
    "    invest_count = train_params['invest_count']\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_count = len(dataY);\n",
    "    train_size = int(data_count * train_params['train_percent'] / 100)\n",
    "    train_last = data_count-invest_count;\n",
    "    \n",
    "    trainX = np.array(dataX[0:train_size])\n",
    "    testX = np.array(dataX[train_size:train_last])\n",
    "    investX = np.array(dataX[train_last:data_count])\n",
    "    \n",
    "    trainY = np.array(dataY[0:train_size])\n",
    "    testY = np.array(dataY[train_size:train_last])\n",
    "    investY = np.array(dataY[train_last:data_count])\n",
    "    \n",
    "    trainCloses = np.array( y[seq_length-1:train_size+seq_length-1])\n",
    "    testCloses = np.array(dataY[train_size-1:train_last-1])\n",
    "    investCloses = np.array(dataY[train_last-1:data_count-1])\n",
    "    investRealCloses = np.array(data['Close'][train_last-1+seq_length:data_count-1+seq_length].values)\n",
    "    \n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY, 'trainCloses': trainCloses,\n",
    "        'testX': testX, 'testY': testY, 'testCloses' : testCloses,\n",
    "        'investX': investX,'investY': investY, 'investCloses': investCloses, 'investRealCloses': investRealCloses\n",
    "    }\n",
    "\n",
    "# train, test데이터로 만든다.\n",
    "def get_train_test(data, train_params) :\n",
    "    scaled_data = get_scaled_data(data)\n",
    "    dataX, dataY, y = get_dataXY(scaled_data, train_params)\n",
    "    return split_train_test(dataX, dataY, train_params, data, y)\n",
    "\n",
    "# 텐스플로우 변수관계 그래프롤 그린다.\n",
    "def draw_graph(train_params) :\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    hidden_dims = train_params['hidden_dims']\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "    X_closes = tf.placeholder(tf.float32, [None, 1])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "    output_keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    cells = []\n",
    "    for n in hidden_dims :\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_units=n, activation=tf.tanh)\n",
    "        dropout_cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=output_keep_prob)\n",
    "        cells.append(dropout_cell)\n",
    "    stacked_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(stacked_rnn_cell, X, dtype=tf.float32) \n",
    "    Y_pred = tf.contrib.layers.fully_connected(\n",
    "        outputs[:, -1], train_params['output_dim'], activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "    # cost/loss\n",
    "    not_equal = tf.cast(tf.not_equal(tf.sign(X_closes-Y), tf.sign(X_closes-Y_pred)), tf.float32)\n",
    "    loss = tf.reduce_sum(tf.square(Y_pred - Y) + not_equal)\n",
    "        \n",
    "    optimizer = tf.train.AdamOptimizer(train_params['learning_rate'])\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # RMSE\n",
    "    targets = tf.placeholder(tf.float32, [None, 1])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "    direction_error = tf.reduce_mean(\n",
    "        tf.cast(tf.not_equal(tf.sign(X_closes-targets), tf.sign(X_closes-predictions)), tf.float32))\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'output_keep_prob': output_keep_prob,\n",
    "        'train': train,\n",
    "        'loss' : loss,\n",
    "        'Y_pred': Y_pred,\n",
    "        'targets': targets,\n",
    "        'rmse' : rmse,\n",
    "        'predictions': predictions,\n",
    "        'X_closes' : X_closes,\n",
    "        'direction_error' : direction_error\n",
    "    }\n",
    "\n",
    "def draw_plot(rmse_vals, test_predict, testY, train_params) :\n",
    "    print('seq_length : ', train_params['seq_length'])\n",
    "    print('hidden_dims : ', train_params['hidden_dims'])\n",
    "    print('dropout_keep : ', train_params['dropout_keep'])\n",
    "    print('rmse_vals : ', rmse_vals[len(rmse_vals)-1])\n",
    "    plt.figure(1)\n",
    "    plt.plot(rmse_vals, 'gold')\n",
    "    plt.xlabel('Epoch(x100)')\n",
    "    plt.ylabel('Root Mean Square Error')\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(testY, 'r')\n",
    "    plt.plot(test_predict, 'b')\n",
    "    plt.xlabel('Time Period')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.show()\n",
    "\n",
    "# 학습을 시킨다.\n",
    "def let_training(data_params, train_params, graph_params, comp_code) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    output_keep_prob = graph_params['output_keep_prob']\n",
    "    train = graph_params['train']\n",
    "    loss = graph_params['loss']\n",
    "    trainX = data_params['trainX']\n",
    "    trainY = data_params['trainY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    trainCloses = data_params['trainCloses']\n",
    "    testCloses = data_params['testCloses']\n",
    "    \n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    targets = graph_params['targets']\n",
    "    rmse = graph_params['rmse']\n",
    "    predictions = graph_params['predictions']\n",
    "    X_closes = graph_params['X_closes']\n",
    "    direction_error = graph_params['direction_error']\n",
    "    loss_up_count = train_params['loss_up_count']\n",
    "    dropout_keep = train_params['dropout_keep']\n",
    "    \n",
    "#     saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # Training step\n",
    "        min_rmse_val = 999999\n",
    "        min_direction_error_val = 999999\n",
    "        less_cnt = 0\n",
    "        train_count = 0\n",
    "        rmse_vals = []\n",
    "        \n",
    "        for i in range(train_params['iterations']):\n",
    "            _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY, X_closes: trainCloses, output_keep_prob: dropout_keep})\n",
    "            if i % 100 == 0 :\n",
    "                test_predict = sess.run(Y_pred, feed_dict={X: testX, output_keep_prob: 1.0})\n",
    "                rmse_val, direction_error_val = sess.run([rmse,  direction_error], feed_dict={targets: testY, predictions: test_predict, X_closes: testCloses}) \n",
    "                #print(step_loss, rmse_val, direction_error_val)\n",
    "                #if rmse_val < min_rmse_val :\n",
    "                rmse_vals.append(rmse_val)\n",
    "                if direction_error_val + rmse_val < min_direction_error_val + min_rmse_val :\n",
    "                #if direction_error_val < min_direction_error_val :\n",
    "#                     tf.add_to_collection(\"X\", X)\n",
    "#                     tf.add_to_collection(\"X_closes\", X_closes)\n",
    "#                     tf.add_to_collection(\"Y\", Y)\n",
    "#                     tf.add_to_collection(\"train\", train)\n",
    "#                     tf.add_to_collection(\"Y_pred\", Y_pred)\n",
    "#                     tf.add_to_collection(\"output_keep_prob\", output_keep_prob)\n",
    "#                     saver.save(sess, \"./sessions/\" + str(comp_code) + \".ckpt\")\n",
    "                    less_cnt = 0\n",
    "                    train_count = i;\n",
    "                    max_test_predict, min_rmse_val, min_direction_error_val = test_predict, rmse_val, direction_error_val\n",
    "                else :\n",
    "                    less_cnt += 1\n",
    "                if less_cnt > loss_up_count :\n",
    "                    break\n",
    "        #draw_plot(rmse_vals, max_test_predict, testY, train_params) \n",
    "        return max_test_predict, min_rmse_val, min_direction_error_val, train_count \n",
    "\n",
    "# 그래프를 그리고 학습을 시킨다.    \n",
    "def let_leaning(data_params, train_params, comp_code):\n",
    "    graph_params = draw_graph(train_params)\n",
    "    return let_training(data_params, train_params, graph_params, comp_code)\n",
    "\n",
    "def to_dataFrame(data, columns) :\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# excel로 저장한다.\n",
    "def save_excel(df_data, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    df_data.to_excel(writer,'Sheet1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "# 예측 값에 따라 매수 매도를 실행한다.    \n",
    "def let_invest_money(invest_predict, now_scaled_close, now_close, train_params, now_money, now_stock_cnt) :\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    pie_percent = train_params['pie_percent']\n",
    "    invest_min_percent = train_params['invest_min_percent']\n",
    "    \n",
    "    ratio = (invest_predict - now_scaled_close) /now_scaled_close * 100\n",
    "    \n",
    "    if ratio > invest_min_percent :\n",
    "        cnt = math.floor(now_money/now_close)\n",
    "        if cnt > 0 :\n",
    "            pie = now_close * pie_percent/100\n",
    "            now_money -= (now_close + pie) * cnt\n",
    "            now_stock_cnt += cnt\n",
    "    elif ratio < -invest_min_percent :\n",
    "        if now_stock_cnt > 0 :\n",
    "            now_money += to_money(now_close, now_stock_cnt, train_params)\n",
    "            now_stock_cnt = 0\n",
    "    #print(now_money, now_stock_cnt, now_scaled_close, invest_predict, data_params['testY'])\n",
    "    return now_money, now_stock_cnt\n",
    "\n",
    "# 주식매도를 해서 돈으로 바꾼다.\n",
    "def to_money(now_stock_cnt, now_close, train_params) :\n",
    "    money = 0\n",
    "    if now_stock_cnt > 0 :\n",
    "        pie_percent = train_params['pie_percent'] \n",
    "        tax_percent = train_params['tax_percent']\n",
    "        \n",
    "        pie = now_close * pie_percent/100\n",
    "        tax = now_close * tax_percent/100\n",
    "        money = (now_close - (pie + tax)) * now_stock_cnt\n",
    "    return money\n",
    "    \n",
    "# 학습 후 모의 주식 거래를 한다.\n",
    "def let_invest(row, train_params, data_params, train_cnt):\n",
    "    comp_code = row['종목코드']\n",
    "    invest_count = train_params['invest_count']\n",
    "    invest_money = train_params['invest_money']\n",
    "    dropout_keep = train_params['dropout_keep']\n",
    "    \n",
    "    investX = data_params['investX']\n",
    "    investCloses = data_params['investCloses']\n",
    "    investRealCloses = data_params['investRealCloses']\n",
    "    investX = data_params['investX']\n",
    "    investY = data_params['investY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    testCloses = data_params['testCloses']\n",
    "    #print(investRealCloses)\n",
    "    \n",
    "    now_stock_cnt = 0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        saver.restore(sess, \"./sessions/\" + str(comp_code) + \".ckpt\") \n",
    "        X = tf.get_collection('X')[0]\n",
    "        X_closes = tf.get_collection('X_closes')[0]\n",
    "        Y = tf.get_collection('Y')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "        Y_pred = tf.get_collection('Y_pred')[0]\n",
    "        output_keep_prob = tf.get_collection('output_keep_prob')[0]\n",
    "        \n",
    "        for i in range(int(train_cnt/10)):\n",
    "            sess.run(train, feed_dict={X: testX, Y: testY, X_closes: testCloses, output_keep_prob: dropout_keep})\n",
    "        \n",
    "        for i in range(invest_count) :\n",
    "            np.array([1, 2, 3], ndmin=2)\n",
    "            invest_predicts = sess.run(Y_pred, feed_dict={X: investX[i:i+1], output_keep_prob: 1.0})\n",
    "            \n",
    "            invest_predict = invest_predicts[0][0];\n",
    "            now_scaled_close = investCloses[0][0]\n",
    "            now_close = investRealCloses[i]\n",
    "            #print(invest_predict, now_scaled_close, now_close)\n",
    "            invest_money, now_stock_cnt = let_invest_money(invest_predict, now_scaled_close, now_close,\n",
    "                                                           train_params, invest_money, now_stock_cnt)\n",
    "            for i in range(int(train_cnt/100)):\n",
    "                sess.run(train, feed_dict={X: investX[i:i+1], Y: investY[i:i+1], X_closes: investCloses[i:i+1], \n",
    "                                           output_keep_prob: dropout_keep})\n",
    "            #break\n",
    "        invest_money += to_money(now_stock_cnt, now_close, train_params)\n",
    "    #print(now_money)\n",
    "    return invest_money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 정의 \n",
    "# train Parameters\n",
    "train_params = {\n",
    "    'seq_length' : 28, # 시퀀스 갯수\n",
    "    'data_dim' : 5,    # 입력 데이터 갯수\n",
    "    'hidden_dims' : [128, 64, 128, 512, 128, 32, 128, 64, 128, 32],  # 히든 레이어 갯수 \n",
    "    'dropout_keep' : 0.5, # dropout \n",
    "    'output_dim' : 1,  # 출력 데이터 갯수\n",
    "    'learning_rate' : 0.0001, \n",
    "    'iterations' : 100000,  # 최대 훈련 반복횟수\n",
    "    'train_percent' : 70.0, # 훈련 데이터 퍼센트\n",
    "    'loss_up_count' : 10, # early stopping\n",
    "    #'invest_corp_count' : 100, # 투자하는 주식회사 갯수\n",
    "    'invest_count' : 50,  # 투자 횟수\n",
    "    'invest_money' : 1000000, # 각 주식에 모의투자할 금액\n",
    "    'pie_percent' : 0.015, # 투자시 발생하는 수수료\n",
    "    'tax_percent' : 0.5,   # 매도시 발생하는 세금\n",
    "    'invest_min_percent' : 0.6 # 투자를 하는 최소 간격 퍼센트 \n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식회사 데이터\n",
    "corporations = pd.read_excel('./corporations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068\n"
     ]
    }
   ],
   "source": [
    "stock_corps = corporations.query(\"상장일<'2005-01-01'  \")[['회사명', '종목코드']]\n",
    "print(len(stock_corps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no seq_length hidden_dims dropout_keep rmse direction_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 13 [112, 80, 16, 48] 0.1 0.1174687718351682 0.5300546487172445\n",
      "51 13 [48, 16, 80, 48, 112, 112, 64] 0.1 0.1344033976395925 0.5300546487172445\n",
      "52 13 [112] 0.4 0.0335781704634428 0.5093676745891571\n",
      "53 13 [112, 80, 16, 48] 0.4 0.05343951905767123 0.5187353591124216\n",
      "54 13 [48, 16, 80, 48, 112, 112, 64] 0.4 0.06037825345993042 0.5226385593414307\n",
      "55 13 [112] 0.7 0.03530954259137312 0.5054644842942556\n",
      "56 13 [112, 80, 16, 48] 0.7 0.04803303504983584 0.5238095124562582\n",
      "57 13 [48, 16, 80, 48, 112, 112, 64] 0.7 0.05852124219139417 0.5202966332435608\n",
      "58 13 [112] 1.0 0.030845162148276966 0.505074163277944\n",
      "59 13 [112, 80, 16, 48] 1.0 0.04922148212790489 0.5214675962924957\n",
      "60 13 [48, 16, 80, 48, 112, 112, 64] 1.0 0.05741334209839503 0.518345057964325\n",
      "61 16 [112] 0.1 0.043507410834232964 0.5224697291851044\n",
      "62 16 [112, 80, 16, 48] 0.1 0.1271460379163424 0.5306760470072428\n",
      "63 16 [48, 16, 80, 48, 112, 112, 64] 0.1 0.13025227437416712 0.5236420631408691\n",
      "64 16 [112] 0.4 0.03644092256824175 0.5123094916343689\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f910914dede8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stock_datail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdata_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection_error_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlet_leaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0msum_rmse_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrmse_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msum_direction_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdirection_error_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-856b22cfe977>\u001b[0m in \u001b[0;36mlet_leaning\u001b[0;34m(data_params, train_params, comp_code)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlet_leaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mgraph_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlet_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_dataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-856b22cfe977>\u001b[0m in \u001b[0;36mlet_training\u001b[0;34m(data_params, train_params, graph_params, comp_code)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_closes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainCloses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout_keep\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼 파라미터를 찾는다. - 전체 범위를 광범위하게 테스트\n",
    "hyper_rmses = []\n",
    "print('no', 'seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error')\n",
    "use_cnt = 3\n",
    "seq_length_list = list(range(1,20,3))\n",
    "dropout_keep_list = [(n+1)/10.0 for n in range(0,10,3) ]\n",
    "hidden_dims_list = [[ np.random.randint(1,10)*16 for m in range(n)] for n in range(1,10,3) ]\n",
    "\n",
    "try_no = 1;\n",
    "for params in itertools.product(seq_length_list,dropout_keep_list,hidden_dims_list):\n",
    "    train_params['seq_length'] = params[0]\n",
    "    train_params['dropout_keep'] = params[1]\n",
    "    train_params['hidden_dims'] = params[2]\n",
    "    \n",
    "    no = 0;\n",
    "    sum_rmse_val = 0.0\n",
    "    sum_direction_error = 0.0\n",
    "    for idx, row in stock_corps.iterrows():\n",
    "        comp_code = row['종목코드']\n",
    "        data = get_stock_datail(comp_code)\n",
    "        data_params = get_train_test(data, train_params)\n",
    "        _, rmse_val, direction_error_val, train_cnt = let_leaning(data_params, train_params, comp_code)\n",
    "        sum_rmse_val += rmse_val\n",
    "        sum_direction_error += direction_error_val\n",
    "        #now_money = let_invest(row, train_params, data_params, train_cnt)\n",
    "        #print(sum_rmse_val, sum_direction_error)\n",
    "        if no > use_cnt-2 :\n",
    "            break\n",
    "        no += 1;\n",
    "    rmse = sum_rmse_val/use_cnt\n",
    "    direction_error = sum_direction_error/use_cnt\n",
    "    print(try_no, train_params['seq_length'], train_params['hidden_dims'], \n",
    "                        train_params['dropout_keep'], rmse, direction_error)\n",
    "    hyper_rmses.append([train_params['seq_length'], train_params['hidden_dims'], \n",
    "                        train_params['dropout_keep'], rmse, direction_error])\n",
    "    try_no += 1\n",
    " \n",
    "# seq_length = 7, dropout_keep = 1.0, hidden_dims = [112] 가 선택됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라이터 결과 값을 저장한다.\n",
    "df_hyper_rmses = pd.DataFrame(hyper_rmses, columns=['seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error'])    \n",
    "save_excel(df_hyper_rmses, 'hyper_rmses_wide.xlsx')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[128], [96, 48], [112, 48, 112]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ np.random.randint(1,10)*16 for m in range(n)] for n in range(1,4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no seq_length hidden_dims dropout_keep rmse direction_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 8 [32, 32, 64] 1.0 0.05296915272871653 0.6841900448004404\n",
      "37 9 [128] 0.8 0.04417183933158716 0.673294335603714\n",
      "38 9 [128, 96] 0.8 0.04390620688597361 0.6748538017272949\n",
      "39 9 [32, 32, 64] 0.8 0.05421902736028036 0.6635477642218272\n",
      "40 9 [128] 0.9 0.05331631066898505 0.6729044914245605\n",
      "41 9 [128, 96] 0.9 0.04402166232466698 0.6764132479826609\n",
      "42 9 [32, 32, 64] 0.9 0.053065831462542214 0.6748538017272949\n",
      "43 9 [128] 1.0 0.046463631093502045 0.6693957050641378\n",
      "44 9 [128, 96] 1.0 0.04665865749120712 0.6756335298220316\n",
      "45 9 [32, 32, 64] 1.0 0.05383550003170967 0.686549723148346\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼 파라미터를 찾는다. 2 - 좁혀진 범위에서 촘촘하게 테스트 \n",
    "hyper_rmses = []\n",
    "print('no', 'seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error')\n",
    "use_cnt = 3\n",
    "seq_length_list = list(range(5,10))\n",
    "dropout_keep_list = [(n+1)/10.0 for n in range(7,10) ]\n",
    "hidden_dims_list = [[ np.random.randint(1,5)*32 for m in range(n)] for n in range(1,4) ]\n",
    "\n",
    "try_no = 1;\n",
    "for params in itertools.product(seq_length_list,dropout_keep_list,hidden_dims_list):\n",
    "    train_params['seq_length'] = params[0]\n",
    "    train_params['dropout_keep'] = params[1]\n",
    "    train_params['hidden_dims'] = params[2]\n",
    "    \n",
    "    no = 0;\n",
    "    sum_rmse_val = 0.0\n",
    "    sum_direction_error = 0.0\n",
    "    for idx, row in stock_corps.iterrows():\n",
    "        comp_code = row['종목코드']\n",
    "        data = get_stock_datail(comp_code)\n",
    "        data_params = get_train_test(data, train_params)\n",
    "        _, rmse_val, direction_error_val, train_cnt = let_leaning(data_params, train_params, comp_code)\n",
    "        sum_rmse_val += rmse_val\n",
    "        sum_direction_error += direction_error_val\n",
    "        #now_money = let_invest(row, train_params, data_params, train_cnt)\n",
    "        #print(sum_rmse_val, sum_direction_error)\n",
    "        if no > use_cnt-2 :\n",
    "            break\n",
    "        no += 1;\n",
    "    rmse = sum_rmse_val/use_cnt\n",
    "    direction_error = sum_direction_error/use_cnt\n",
    "    print(try_no, train_params['seq_length'], train_params['hidden_dims'], \n",
    "                        train_params['dropout_keep'], rmse, direction_error)\n",
    "    hyper_rmses.append([train_params['seq_length'], train_params['hidden_dims'], \n",
    "                        train_params['dropout_keep'], rmse, direction_error])\n",
    "    try_no += 1\n",
    "\n",
    "# seq_length = 5, dropout_keep = 0.8, hidden_dims = [96, 64] 가 선택됨     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라이터 결과 값을 저장한다.\n",
    "df_hyper_rmses = pd.DataFrame(hyper_rmses, columns=['seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error'])    \n",
    "save_excel(df_hyper_rmses, 'hyper_rmses_select.xlsx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no seq_length hidden_dims dropout_keep rmse direction_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5 [96] 0.8 0.030787284175554912 0.5186915894349416\n",
      "2 5 [128, 32] 0.8 0.03276223627229532 0.5054517090320587\n",
      "3 5 [128, 128, 64] 0.8 0.03636598959565163 0.514018694559733\n",
      "1 5 [96] 0.8 0.03931254396835963 0.5081775784492493\n",
      "2 5 [96, 32] 0.8 0.036602544908722244 0.5132398704687754\n",
      "3 5 [128, 128, 32] 0.8 0.03413493558764458 0.5144080917040507\n",
      "1 5 [96] 0.8 0.030777699624498684 0.5105140209197998\n",
      "2 5 [64, 64] 0.8 0.0422152200092872 0.5198598106702169\n",
      "3 5 [128, 32, 32] 0.8 0.03628784790635109 0.5116822322209676\n",
      "1 5 [96] 0.8 0.0405144194761912 0.5085669755935669\n",
      "2 5 [32, 64] 0.8 0.03771666002770265 0.506619930267334\n",
      "3 5 [128, 96, 64] 0.8 0.035910896956920624 0.5050623019536337\n",
      "1 5 [64] 0.8 0.027002083758513134 0.5093457897504171\n",
      "2 5 [128, 64] 0.8 0.03963865153491497 0.5050623118877411\n",
      "3 5 [64, 96, 128] 0.8 0.03741348721086979 0.5031152566274008\n",
      "1 5 [64] 0.8 0.034928091491262116 0.5120716591676077\n",
      "2 5 [32, 64] 0.8 0.03796032629907131 0.5085669855276743\n",
      "3 5 [32, 32, 96] 0.8 0.040620225171248116 0.5077881614367167\n",
      "1 5 [128] 0.8 0.03246593661606312 0.5186915795008341\n",
      "2 5 [96, 128] 0.8 0.04024869265655676 0.5038940906524658\n",
      "3 5 [32, 32, 96] 0.8 0.03818400825063387 0.5042834877967834\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼 파라미터를 찾는다. 3 - hidden_dims 를 몇 번 더 반복해본다.(값을 랜덤으로 했기 때문에...)\n",
    "hyper_rmses = []\n",
    "print('no', 'seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error')\n",
    "use_cnt = 3\n",
    "\n",
    "for j in range(7) :\n",
    "\n",
    "    seq_length_list = [5]\n",
    "    dropout_keep_list = [0.8]\n",
    "    hidden_dims_list = [[ np.random.randint(1,5)*32 for m in range(n)] for n in range(1,4) ]\n",
    "\n",
    "    try_no = 1;\n",
    "    for params in itertools.product(seq_length_list,dropout_keep_list,hidden_dims_list):\n",
    "        train_params['seq_length'] = params[0]\n",
    "        train_params['dropout_keep'] = params[1]\n",
    "        train_params['hidden_dims'] = params[2]\n",
    "\n",
    "        no = 0;\n",
    "        sum_rmse_val = 0.0\n",
    "        sum_direction_error = 0.0\n",
    "        for idx, row in stock_corps.iterrows():\n",
    "            comp_code = row['종목코드']\n",
    "            data = get_stock_datail(comp_code)\n",
    "            data_params = get_train_test(data, train_params)\n",
    "            _, rmse_val, direction_error_val, train_cnt = let_leaning(data_params, train_params, comp_code)\n",
    "            sum_rmse_val += rmse_val\n",
    "            sum_direction_error += direction_error_val\n",
    "            #now_money = let_invest(row, train_params, data_params, train_cnt)\n",
    "            #print(sum_rmse_val, sum_direction_error)\n",
    "            if no > use_cnt-2 :\n",
    "                break\n",
    "            no += 1;\n",
    "        rmse = sum_rmse_val/use_cnt\n",
    "        direction_error = sum_direction_error/use_cnt\n",
    "        print(try_no, train_params['seq_length'], train_params['hidden_dims'], \n",
    "                            train_params['dropout_keep'], rmse, direction_error)\n",
    "        hyper_rmses.append([train_params['seq_length'], train_params['hidden_dims'], \n",
    "                            train_params['dropout_keep'], rmse, direction_error])\n",
    "        try_no += 1\n",
    "\n",
    "# seq_length = 5, dropout_keep = 0.8, hidden_dims = [128, 32] 가 선택됨         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라이터 결과 값을 저장한다.\n",
    "df_hyper_rmses = pd.DataFrame(hyper_rmses, columns=['seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error'])    \n",
    "save_excel(df_hyper_rmses, 'hyper_rmses_select_hidden_dims.xlsx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no seq_length hidden_dims dropout_keep rmse direction_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5 [64] 0.8 0.028680693358182907 0.5144081115722656\n",
      "2 5 [128, 32] 0.8 0.03138316671053568 0.5085669755935669\n",
      "3 5 [96, 64] 0.8 0.030631134907404583 0.5101246138413748\n",
      "4 5 [64, 96, 128] 0.8 0.03665653429925442 0.504672904809316\n",
      "5 5 [96] 0.8 0.03152791472772757 0.508956382671992\n",
      "6 5 [128, 96, 64] 0.8 0.031166815509398777 0.5081775784492493\n",
      "7 5 [32] 0.8 0.03075985920925935 0.5101246138413748\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼 파라미터를 찾는다. 3 - hidden_dims 를 몇 번 더 반복해본다.(값을 랜덤으로 했기 때문에...) - 최종후보 \n",
    "hyper_rmses = []\n",
    "print('no', 'seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error')\n",
    "use_cnt = 3\n",
    "\n",
    "seq_length_list = [5]\n",
    "dropout_keep_list = [0.8]\n",
    "hidden_dims_list = [[64],[128,32],[96, 64], [64, 96, 128], [96], [128, 96, 64], [32]]\n",
    "\n",
    "try_no = 1;\n",
    "for params in itertools.product(seq_length_list,dropout_keep_list,hidden_dims_list):\n",
    "    train_params['seq_length'] = params[0]\n",
    "    train_params['dropout_keep'] = params[1]\n",
    "    train_params['hidden_dims'] = params[2]\n",
    "\n",
    "    no = 0;\n",
    "    sum_rmse_val = 0.0\n",
    "    sum_direction_error = 0.0\n",
    "    for idx, row in stock_corps.iterrows():\n",
    "        comp_code = row['종목코드']\n",
    "        data = get_stock_datail(comp_code)\n",
    "        data_params = get_train_test(data, train_params)\n",
    "        _, rmse_val, direction_error_val, train_cnt = let_leaning(data_params, train_params, comp_code)\n",
    "        sum_rmse_val += rmse_val\n",
    "        sum_direction_error += direction_error_val\n",
    "        #now_money = let_invest(row, train_params, data_params, train_cnt)\n",
    "        #print(sum_rmse_val, sum_direction_error)\n",
    "        if no > use_cnt-2 :\n",
    "            break\n",
    "        no += 1;\n",
    "    rmse = sum_rmse_val/use_cnt\n",
    "    direction_error = sum_direction_error/use_cnt\n",
    "    print(try_no, train_params['seq_length'], train_params['hidden_dims'], \n",
    "                        train_params['dropout_keep'], rmse, direction_error)\n",
    "    hyper_rmses.append([train_params['seq_length'], train_params['hidden_dims'], \n",
    "                        train_params['dropout_keep'], rmse, direction_error])\n",
    "    try_no += 1\n",
    "    \n",
    "# seq_length = 5, dropout_keep = 0.8, hidden_dims = [128, 96, 64] 가 선택됨     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라이터 결과 값을 저장한다.\n",
    "df_hyper_rmses = pd.DataFrame(hyper_rmses, columns=['seq_length', 'hidden_dims', 'dropout_keep', 'rmse', 'direction_error'])    \n",
    "save_excel(df_hyper_rmses, 'hyper_rmses_select_hidden_dims_last.xlsx')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
