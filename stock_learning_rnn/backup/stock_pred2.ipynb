{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_zip = zipfile.ZipFile('./Stock_Dataset(2017_07_06).zip')\n",
    "fantasy_zip.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Using cached https://files.pythonhosted.org/packages/07/e6/e95c4eec6221bfd8528bcc4ea252a850bffcc4be88ebc367e23a1a84b0bb/xlrd-1.1.0-py2.py3-none-any.whl\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "Collecting jdcal (from openpyxl)\n",
      "  Using cached https://files.pythonhosted.org/packages/a0/38/dcf83532480f25284f3ef13f8ed63e03c58a65c9d3ba2a6a894ed9497207/jdcal-1.4-py2.py3-none-any.whl\n",
      "\u001b[31mmxnet-cu80 1.1.0 has requirement numpy<=1.13.3, but you'll have numpy 1.14.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: et-xmlfile, jdcal, openpyxl\n",
      "Successfully installed et-xmlfile-1.0.1 jdcal-1.4 openpyxl-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 메소드 정의 \n",
    "# 상세 데이터를 가져온다.\n",
    "def get_stock_datail(comp_code) :\n",
    "    code = format(comp_code, \"06d\");\n",
    "    return pd.read_csv('./data/' + code + '.csv')\n",
    "\n",
    "# matrix 데이터로 변경한다.\n",
    "def to_ndarray(cols_data) :\n",
    "    if isinstance(cols_data, Series):\n",
    "        return np.reshape(list(cols_data), (-1,1))\n",
    "    elif isinstance(cols_data, DataFrame):\n",
    "        return cols_data.as_matrix()\n",
    "\n",
    "# 컬럼을 스케일링을 시킨다.\n",
    "def get_scaled_cols(data, column_name) :\n",
    "    scale_data = to_ndarray(data[column_name])\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(scale_data);\n",
    "\n",
    "# 데이터를 스케일링 시킨다.\n",
    "def get_scaled_data(data) :\n",
    "    scaled_data = data.copy()\n",
    "    scaled_data['Close'] = get_scaled_cols(scaled_data, 'Close')\n",
    "    scaled_data['Open'] = get_scaled_cols(scaled_data, 'Open')\n",
    "    scaled_data['High'] = get_scaled_cols(scaled_data, 'High')\n",
    "    scaled_data['Low'] = get_scaled_cols(scaled_data, 'Low')\n",
    "    scaled_data['Volume'] = get_scaled_cols(scaled_data, 'Volume')\n",
    "    return scaled_data;\n",
    "\n",
    "# RNN을 위한 데이터로 만든다. \n",
    "def get_dataXY(data, train_params) :\n",
    "    x = to_ndarray(data[['Open', 'High', 'Low', 'Volume', 'Close']])\n",
    "    y = to_ndarray(data['Close'])\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    seq_length = train_params['seq_length']\n",
    "    for i in range(0, len(y) - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        _y = y[i + seq_length] # Next close price\n",
    "        #print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return dataX, dataY, y\n",
    "\n",
    "# train 및 test 데이터로 나눈다.\n",
    "def split_train_test(dataX, dataY, train_params, data, y) :\n",
    "    invest_count = train_params['invest_count']\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_count = len(dataY);\n",
    "    train_size = int(data_count * train_params['train_percent'] / 100)\n",
    "    train_last = data_count-invest_count;\n",
    "    \n",
    "    trainX = np.array(dataX[0:train_size])\n",
    "    testX = np.array(dataX[train_size:train_last])\n",
    "    investX = np.array(dataX[train_last:data_count])\n",
    "    \n",
    "    trainY = np.array(dataY[0:train_size])\n",
    "    testY = np.array(dataY[train_size:train_last])\n",
    "    investY = np.array(dataY[train_last:data_count])\n",
    "    \n",
    "    trainCloses = np.array( y[seq_length-1:train_size+seq_length-1])\n",
    "    testCloses = np.array(dataY[train_size-1:train_last-1])\n",
    "    investCloses = np.array(dataY[train_last-1:data_count-1])\n",
    "    investRealCloses = np.array(data['Close'][train_last-1+seq_length:data_count-1+seq_length].values)\n",
    "    \n",
    "    return {\n",
    "        'trainX': trainX, 'trainY': trainY, 'trainCloses': trainCloses,\n",
    "        'testX': testX, 'testY': testY, 'testCloses' : testCloses,\n",
    "        'investX': investX,'investY': investY, 'investCloses': investCloses, 'investRealCloses': investRealCloses\n",
    "    }\n",
    "\n",
    "# train, test데이터로 만든다.\n",
    "def get_train_test(data, train_params) :\n",
    "    scaled_data = get_scaled_data(data)\n",
    "    dataX, dataY, y = get_dataXY(scaled_data, train_params)\n",
    "    return split_train_test(dataX, dataY, train_params, data, y)\n",
    "\n",
    "# 텐스플로우 변수관계 그래프롤 그린다.\n",
    "def draw_graph(train_params) :\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    hidden_dims = train_params['hidden_dims']\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "    X_closes = tf.placeholder(tf.float32, [None, 1])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "    output_keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    cells = []\n",
    "    for n in hidden_dims :\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_units=n, activation=tf.tanh)\n",
    "        dropout_cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=output_keep_prob)\n",
    "        cells.append(dropout_cell)\n",
    "    stacked_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(dropout_cell, X, dtype=tf.float32) \n",
    "    Y_pred = tf.contrib.layers.fully_connected(\n",
    "        outputs[:, -1], train_params['output_dim'], activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "    # cost/loss\n",
    "    not_equal = tf.cast(tf.not_equal(tf.sign(X_closes-Y), tf.sign(X_closes-Y_pred)), tf.float32)\n",
    "    loss = tf.reduce_sum(tf.square(Y_pred - Y) + not_equal)\n",
    "        \n",
    "    optimizer = tf.train.AdamOptimizer(train_params['learning_rate'])\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # RMSE\n",
    "    targets = tf.placeholder(tf.float32, [None, 1])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "    direction_error = tf.reduce_mean(\n",
    "        tf.cast(tf.not_equal(tf.sign(X_closes-targets), tf.sign(X_closes-predictions)), tf.float32))\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'output_keep_prob': output_keep_prob,\n",
    "        'train': train,\n",
    "        'loss' : loss,\n",
    "        'Y_pred': Y_pred,\n",
    "        'targets': targets,\n",
    "        'rmse' : rmse,\n",
    "        'predictions': predictions,\n",
    "        'X_closes' : X_closes,\n",
    "        'direction_error' : direction_error\n",
    "    }\n",
    "\n",
    "# 학습을 시킨다.\n",
    "def let_training(data_params, train_params, graph_params, comp_code) :\n",
    "    X = graph_params['X']\n",
    "    Y = graph_params['Y']\n",
    "    output_keep_prob = graph_params['output_keep_prob']\n",
    "    train = graph_params['train']\n",
    "    loss = graph_params['loss']\n",
    "    trainX = data_params['trainX']\n",
    "    trainY = data_params['trainY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    trainCloses = data_params['trainCloses']\n",
    "    testCloses = data_params['testCloses']\n",
    "    \n",
    "    Y_pred = graph_params['Y_pred']\n",
    "    targets = graph_params['targets']\n",
    "    rmse = graph_params['rmse']\n",
    "    predictions = graph_params['predictions']\n",
    "    X_closes = graph_params['X_closes']\n",
    "    direction_error = graph_params['direction_error']\n",
    "    loss_up_count = train_params['loss_up_count']\n",
    "    dropout_keep = train_params['dropout_keep']\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # Training step\n",
    "        min_rmse_val = 999999\n",
    "        min_direction_error_val = 999999\n",
    "        less_cnt = 0\n",
    "        train_count = 0\n",
    "        for i in range(train_params['iterations']):\n",
    "            _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY, X_closes: trainCloses, \n",
    "                                                              output_keep_prob: dropout_keep})\n",
    "            if i % 100 == 0 :\n",
    "                test_predict = sess.run(Y_pred, feed_dict={X: testX, output_keep_prob: 1.0})\n",
    "                rmse_val, direction_error_val = sess.run([rmse,  direction_error], \n",
    "                                                feed_dict={targets: testY, predictions: test_predict, X_closes: testCloses}) \n",
    "                #print(step_loss, rmse_val, direction_error_val)\n",
    "                #if rmse_val < min_rmse_val :\n",
    "                #if direction_error_val + rmse_val < min_direction_error_val + min_rmse_val :\n",
    "                if direction_error_val < min_direction_error_val :\n",
    "                    tf.add_to_collection(\"X\", X)\n",
    "                    tf.add_to_collection(\"X_closes\", X_closes)\n",
    "                    tf.add_to_collection(\"Y\", Y)\n",
    "                    tf.add_to_collection(\"train\", train)\n",
    "                    tf.add_to_collection(\"Y_pred\", Y_pred)\n",
    "                    tf.add_to_collection(\"output_keep_prob\", output_keep_prob)\n",
    "                    saver.save(sess, \"./sessions/\" + str(comp_code) + \".ckpt\")\n",
    "                    less_cnt = 0\n",
    "                    train_count = i;\n",
    "                    max_test_predict, min_rmse_val, min_direction_error_val = test_predict, rmse_val, direction_error_val\n",
    "                else :\n",
    "                    less_cnt += 1\n",
    "                if less_cnt > loss_up_count :\n",
    "                    break\n",
    "        \n",
    "        return max_test_predict, min_rmse_val, min_direction_error_val, train_count \n",
    "\n",
    "# 그래프를 그리고 학습을 시킨다.    \n",
    "def let_leaning(data_params, train_params, comp_code):\n",
    "    graph_params = draw_graph(train_params)\n",
    "    return let_training(data_params, train_params, graph_params, comp_code)\n",
    "\n",
    "def to_dataFrame(data, columns) :\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# excel로 저장한다.\n",
    "def save_excel(df_data, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    df_data.to_excel(writer,'Sheet1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "# 예측 값에 따라 매수 매도를 실행한다.    \n",
    "def let_invest_money(invest_predict, now_scaled_close, now_close, train_params, now_money, now_stock_cnt) :\n",
    "    seq_length = train_params['seq_length']\n",
    "    data_dim = train_params['data_dim']\n",
    "    pie_percent = train_params['pie_percent']\n",
    "    invest_min_percent = train_params['invest_min_percent']\n",
    "    \n",
    "    ratio = (invest_predict - now_scaled_close) /now_scaled_close * 100\n",
    "    \n",
    "    if ratio > invest_min_percent :\n",
    "        cnt = math.floor(now_money/now_close)\n",
    "        if cnt > 0 :\n",
    "            pie = now_close * pie_percent/100\n",
    "            now_money -= (now_close + pie) * cnt\n",
    "            now_stock_cnt += cnt\n",
    "    elif ratio < -invest_min_percent :\n",
    "        if now_stock_cnt > 0 :\n",
    "            now_money += to_money(now_close, now_stock_cnt, train_params)\n",
    "            now_stock_cnt = 0\n",
    "    #print(now_money, now_stock_cnt, now_scaled_close, invest_predict, data_params['testY'])\n",
    "    return now_money, now_stock_cnt\n",
    "\n",
    "# 주식매도를 해서 돈으로 바꾼다.\n",
    "def to_money(now_stock_cnt, now_close, train_params) :\n",
    "    money = 0\n",
    "    if now_stock_cnt > 0 :\n",
    "        pie_percent = train_params['pie_percent'] \n",
    "        tax_percent = train_params['tax_percent']\n",
    "        \n",
    "        pie = now_close * pie_percent/100\n",
    "        tax = now_close * tax_percent/100\n",
    "        money = (now_close - (pie + tax)) * now_stock_cnt\n",
    "    return money\n",
    "    \n",
    "# 학습 후 모의 주식 거래를 한다.\n",
    "def let_invest(row, train_params, data_params, train_cnt):\n",
    "    comp_code = row['종목코드']\n",
    "    invest_count = train_params['invest_count']\n",
    "    invest_money = train_params['invest_money']\n",
    "    dropout_keep = train_params['dropout_keep']\n",
    "    \n",
    "    investX = data_params['investX']\n",
    "    investCloses = data_params['investCloses']\n",
    "    investRealCloses = data_params['investRealCloses']\n",
    "    investX = data_params['investX']\n",
    "    investY = data_params['investY']\n",
    "    testX = data_params['testX']\n",
    "    testY = data_params['testY']\n",
    "    testCloses = data_params['testCloses']\n",
    "    #print(investRealCloses)\n",
    "    \n",
    "    now_stock_cnt = 0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        saver.restore(sess, \"./sessions/\" + str(comp_code) + \".ckpt\") \n",
    "        X = tf.get_collection('X')[0]\n",
    "        X_closes = tf.get_collection('X_closes')[0]\n",
    "        Y = tf.get_collection('Y')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "        Y_pred = tf.get_collection('Y_pred')[0]\n",
    "        output_keep_prob = tf.get_collection('output_keep_prob')[0]\n",
    "        \n",
    "        for i in range(int(train_cnt/4)):\n",
    "            sess.run(train, feed_dict={X: testX, Y: testY, X_closes: testCloses, output_keep_prob: dropout_keep})\n",
    "        \n",
    "        for i in range(invest_count) :\n",
    "            np.array([1, 2, 3], ndmin=2)\n",
    "            invest_predicts = sess.run(Y_pred, feed_dict={X: investX[i:i+1], output_keep_prob: 1.0})\n",
    "            \n",
    "            invest_predict = invest_predicts[0][0];\n",
    "            now_scaled_close = investCloses[0][0]\n",
    "            now_close = investRealCloses[i]\n",
    "            #print(invest_predict, now_scaled_close, now_close)\n",
    "            invest_money, now_stock_cnt = let_invest_money(invest_predict, now_scaled_close, now_close,\n",
    "                                                           train_params, invest_money, now_stock_cnt)\n",
    "            for i in range(int(train_cnt/10)):\n",
    "                sess.run(train, feed_dict={X: investX[i:i+1], Y: investY[i:i+1], X_closes: investCloses[i:i+1], \n",
    "                                           output_keep_prob: dropout_keep})\n",
    "            #break\n",
    "        invest_money += to_money(now_stock_cnt, now_close, train_params)\n",
    "    #print(now_money)\n",
    "    return invest_money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 정의 \n",
    "# train Parameters\n",
    "train_params = {\n",
    "    'seq_length' : 7, # 시퀀스 갯수\n",
    "    'data_dim' : 5,    # 입력 데이터 갯수\n",
    "    'hidden_dims' : [128, 64, 128, 512, 128, 32, 128, 64, 128, 32],  # 히든 레이어 갯수 \n",
    "    'dropout_keep' : 0.5, # dropout \n",
    "    'output_dim' : 1,  # 출력 데이터 갯수\n",
    "    'learning_rate' : 0.0001, \n",
    "    'iterations' : 100000,  # 최대 훈련 반복횟수\n",
    "    'train_percent' : 70.0, # 훈련 데이터 퍼센트\n",
    "    'loss_up_count' : 10, # early stopping\n",
    "    #'invest_corp_count' : 100, # 투자하는 주식회사 갯수\n",
    "    'invest_count' : 50,  # 투자 횟수\n",
    "    'invest_money' : 1000000, # 각 주식에 모의투자할 금액\n",
    "    'pie_percent' : 0.015, # 투자시 발생하는 수수료\n",
    "    'tax_percent' : 0.5,   # 매도시 발생하는 세금\n",
    "    'invest_min_percent' : 0.6 # 투자를 하는 최소 간격 퍼센트 \n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식회사 데이터\n",
    "corporations = pd.read_excel('./corporations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_corps = corporations.query(\"상장일<'2005-01-01'  \")[['회사명', '종목코드']]\n",
    "print(len(stock_corps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./sessions/1460.ckpt\n",
      "no code name rmse direction_error invest_result\n",
      "1 1460 BYC 0.02769858 0.53621495 967973.1\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/79160.ckpt\n",
      "2 79160 CJ CGV 0.059864607 0.5035047 1000000\n",
      "INFO:tensorflow:Restoring parameters from ./sessions/5830.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 주식 종목들을 가져와서 학습을 시킨다.\n",
    "comp_rmses = []\n",
    "no = 1;\n",
    "for idx, row in stock_corps.iterrows():\n",
    "    comp_code = row['종목코드']\n",
    "    data = get_stock_datail(comp_code)\n",
    "    data_params = get_train_test(data, train_params)\n",
    "    _, rmse_val, direction_error_val, train_cnt = let_leaning(data_params, train_params, comp_code)\n",
    "    \n",
    "    now_money = let_invest(row, train_params, data_params, train_cnt)\n",
    "    if idx == 0 :\n",
    "        print('no', 'code', 'name', 'rmse', 'direction_error', 'invest_result')\n",
    "    print(no, comp_code, row['회사명'], rmse_val, direction_error_val, now_money)\n",
    "    comp_rmses.append([comp_code, row['회사명'], rmse_val, direction_error_val, now_money])\n",
    "    no += 1\n",
    "    #break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀파일로 저장한다.\n",
    "df_comp_rmses = pd.DataFrame(comp_rmses, columns=['code', 'name', 'rmse', 'direction_error', 'invest_result'])    \n",
    "#df_comp_rmses = df_comp_rmses.sort_values('invest_result', ascending=False)\n",
    "save_excel(df_comp_rmses, 'invest_result3.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
